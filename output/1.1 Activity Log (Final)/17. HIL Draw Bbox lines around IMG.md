# HIL: Draw Bbox lines around IMG


## Content


## 1. Objective and Scope


The objective was to decide how to reliably draw bounding boxes on PDF images around diseases and features detected by ElasticSearch (ES) or NER without destabilising an existing PDF→OCR→JSON pipeline. This would be useful to allow Human-in-th-Loop validation for extracted diseases and features.







Scope:


- Inputs: existing **line spine** and **word spine** with

    doc_id, page_num, line_index, word_index, text, bbox, polygon.
    

- Output: a human-in-the-loop view that highlights detected entities on the page image.





Question: Is a global char-based coordinate system (char_start, char_end) required, or can everything be done with token indices + geometry?







---


## 2. Methods and Process

- Reviewed the current G2 stages:
    - G2_01_build_line_spine: line spine from ALTO.
    - G2_02_build_word_spine: word spine with stable indices and geometry.
- Analysed coordinate systems:
    - Option A: Create two geometric systems in the pipeline and make char spans the primary global index. (char spans are counting characters of text from start to finish)
    - Option B: Create two geometric systems in the pipeline and keep token + geometry as primary, use chars only in a later ES-specific layer.
    - Option C: No change to pipeline. No char spans at all, use tokens exclusively.
- Evaluated each option on:
    - compatibility with the current G0 - G10 pipeline,
    - impact on maintainability and versioning,
    - ability to reliably go **ES/NER → spine → bbox → image**.

    



The analysis was done under a hard constraint: no change to the spine is acceptable unless it delivers clear, measurable benefit.







---


## 3. Key Findings and Technical Outcomes

1. **Token + geometry is enough to solve the core problem.**

    The existing word spine already provides:
    

    - `(doc_id, page_num, line_index, word_index)` + `bbox` / `polygon`.

    This is sufficient to:
    

    - build cleaned text for ES directly from spine tokens,
    - map ES/NER matches back to `word_index_start/end`,
    - derive page and bboxes for HIL highlighting.

    



    In other words: the pipeline can meet the HIL requirement without any char offsets in the spine.
    


    


2. **Global char spans in the spine would be a second, brittle coordinate system.**

    Adding char_start_doc / char_end_doc into the G2 spines would:
    

    - couple the core backbone to a specific cleaning / normalisation regime,
    - require strict versioning and full regeneration on text changes,
    - introduce silent desync risk between chars, cleaning, and geometry. (eg, cleaning out <spans> in html)

    There is no justification to push char offsets into G2_01 / G2_02.
    


    


3. **Char spans** _**will**_ **be added later, but only in an ES prep layer on cleaned text.**

    A downstream ES-specific stage will:
    

    - derive a single canonical clean text view per document from the word and line spine,
    - compute `char_start_clean` and `char_end_clean` for tokens and mentions in that view only,
    - tag these offsets with a `pipeline_run_id` and `cleaning_version`.

    



    Benefits of this design:
    

    - ES and any external tool that expects char spans can work directly on `char_start_clean` and `char_end_clean`.
    - Mapping back to HIL remains via token indices → bboxes; char spans are _auxiliary_, not core.
    - Any change in cleaning is localised to this ES layer and handled via versioning, without touching G2.

    


4. **The current spine remains the primary coordinate system.**

    Geometry + token indices (doc_id, page_num, line_index, word_index) are:
    

    - stable across layout and cleaning changes (as long as tokenisation is fixed),
    - directly usable for human review and visualisation,
    - simpler and safer than a global char-based system in a PDF/OCR context.





Net outcome:


- No changes to G2_01 / G2_02.
- Char spans are introduced only once, after cleaning, as an ES/NER convenience layer on top of the spine – not inside the spine itself.

---


## 4. Critical Reflection

- Char spans are widely used because they are easy to compute on flat text, not because they are robust in multi-stage PDF/OCR pipelines. Creating two co-ordinate systems create complexity and design logistics which has an asymmetrical payoff to the downside. ie Adding a second geometric system to help trace back to the spine adds little value but increase risk of brittleness and maintences substantially.
- In this context, global char offsets:
    - couple the system to a single text representation,
    - do not help with geometry,
    - and age badly when cleaning changes.
- For this pipeline, they would introduce complexity and failure modes **with no current functional gain**.

    Risk–reward is asymmetric: high downside, negligible upside.
    


The design principle that falls out of this:






> _Do not introduce a new coordinate system unless a concrete process demands it and the benefit outweighs the new invariants._
>
> In this pipeline, the primary coordinate system is token + geometry. Char spans, if they ever appear, stay downstream and explicitly versioned.
>
>
>





---


## 5. Next Steps

1. **Lock in the spine as the canonical backbone.**
    - Treat `doc_id`, `page_num`, `line_index`, `word_index`, `bbox`, `polygon` as the **only** primary coordinate system.
    - Document this clearly in the pipeline README:
        - All geometry and human-in-the-loop views are driven from the spine.
        - No char offsets live in G2_01 / G2_02.
2. **Introduce a dedicated ES/NER prep stage with char spans on the cleaned text.**
    - Add a downstream stage (e.g. `Gx_es_prep`) that:
        - takes the spine as input,
        - applies the agreed cleaning and section filtering (HTML stripped, layout junk removed, stable reading order),
        - builds a **single canonical cleaned text view** per document,
        - computes `char_start_clean` and `char_end_clean` for each token and line in that view.
    - This stage writes:
        - `clean_text` (what ES indexes),
        - a token mapping table:
            - `(doc_id, view_id, page_num, line_index, word_index, char_start_clean, char_end_clean)`,
        - and tags everything with `pipeline_run_id` and `cleaning_version`.
3. **Use both tokens and char spans in ES/NER integration, with clear roles.**
    - **For ES and NER themselves (internal + external tools):**
        - Char spans are the natural interface:
            - ES highlighters and many NER libraries emit `(start_char, end_char)` on the input text.
            - Having `char_start_clean` / `char_end_clean` lets you:
                - round-trip ES highlights exactly,
                - plug in off-the-shelf NER models that only speak char offsets,
                - export annotations to third-party tools that expect char spans.
    - **For the pipeline and HIL:**
        - Char spans are **never** the primary key.
        - At ingestion time:
            - ES/NER hits `(doc_id, view_id, char_start_clean, char_end_clean)` are mapped back to

                (page_num, line_index, word_index_start, word_index_end) via the token mapping table.
                

            - HIL and downstream analysis use token indices and bboxes for all visualisation and statistics.
    - Explicit benefits of adding char spans only in this ES layer:
        - Interop: you can plug into standard NLP tooling without rewriting them around token IDs.
        - Comparison: different models or runs can be compared on aligned char spans over the **same** cleaned text view.
        - Export: you can share annotations externally without exposing the internal spine structure.
        - Containment: any drift in cleaning or normalisation only invalidates this ES layer, not the core spine.





This makes the design explicit:


- **Spine** stays clean and stable.
- **Char spans** are added once, **after cleaning**, purely as an ES/NER convenience layer with clear, concrete benefits (tooling, interop, export), and they never contaminate the core pipeline.
















