# PDF to JSON: Templates


## Content


## Pipeline Stage Templates - Quick Reference


### The Core Difference



<table>
  <thead>
    <tr>
      <th>Aspect</th>
      <th>CPU Stage</th>
      <th>GPU Stage</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Scripts</strong></td>
      <td>Single script</td>
      <td>Dispatch + Worker pair</td>
    </tr>
    <tr>
      <td><strong>Invocation</strong></td>
      <td>Per-document subprocess</td>
      <td>Persistent daemon</td>
    </tr>
    <tr>
      <td><strong>Why?</strong></td>
      <td>Simple, stateless</td>
      <td>Model loading is expensive (30-60s)</td>
    </tr>
    <tr>
      <td><strong>Parallelism</strong></td>
      <td><code>parallel_map()</code> within script</td>
      <td>Queue-based job distribution</td>
    </tr>
  </tbody>
</table>



---


## 1. CPU Stage Architecture


### Flow Diagram




~~~{=html}
<pre class="notion-ascii-diagram"><code>┌─────────────────────────────────────────────────────────────┐
│                    ORCHESTRATOR (core.py)                   │
│                                                             │
│  1. Check stages_enabled.GX_YY in resources.yaml            │
│  2. Resolve params from pipelines.GX_YY                     │
│  3. Create CONTRACT JSON (doc_id, inputs, outputs, params)  │
│  4. Write to logs/{doc_id}/contracts/GX_YY_contract.json    │
└─────────────────────────────────────────────────────────────┘
                              │
                              │  subprocess.run([
                              │      &quot;python3&quot;, &quot;GX_YY.py&quot;,
                              │      &quot;--input-dir&quot;, &quot;...&quot;,
                              │      &quot;--output-dir&quot;, &quot;...&quot;,
                              │      &quot;--contract-json&quot;, &quot;...&quot;
                              │  ])
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                    CPU SCRIPT (GX_YY.py)                    │
│                                                             │
│  1. Setup logging                                           │
│  2. Load contract JSON                                      │
│  3. Validate inputs exist                                   │
│  4. Run stage logic (parallel_map if needed)                │
│  5. Validate outputs created                                │
│  6. Exit 0 (success) or 1 (failure)                         │
└─────────────────────────────────────────────────────────────┘
</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
┌─────────────────────────────────────────────────────────────┐
│                    ORCHESTRATOR (core.py)                   │
│                                                             │
│  1. Check stages_enabled.GX_YY in resources.yaml            │
│  2. Resolve params from pipelines.GX_YY                     │
│  3. Create CONTRACT JSON (doc_id, inputs, outputs, params)  │
│  4. Write to logs/\textbraceleft{\textbraceright{}doc_id\textbraceright{}/contracts/GX_YY_contract.json    │
└─────────────────────────────────────────────────────────────┘
                              │
                              │  subprocess.run([
                              │      "python3", "GX_YY.py",
                              │      "--input-dir", "...",
                              │      "--output-dir", "...",
                              │      "--contract-json", "..."
                              │  ])
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                    CPU SCRIPT (GX_YY.py)                    │
│                                                             │
│  1. Setup logging                                           │
│  2. Load contract JSON                                      │
│  3. Validate inputs exist                                   │
│  4. Run stage logic (parallel_map if needed)                │
│  5. Validate outputs created                                │
│  6. Exit 0 (success) or 1 (failure)                         │
└─────────────────────────────────────────────────────────────┘

\end{Verbatim}
~~~




### Data Flow (Golden Rule)




~~~{=html}
<pre class="notion-ascii-diagram"><code>resources.yaml          contract.py              core.py
      │                      │                      │
      │  (param values)      │  (input/output defs) │
      └──────────────────────┴──────────────────────┘
                             │
                             ▼
                ┌────────────────────────┐
                │     CONTRACT JSON      │
                │  ─────────────────────  │
                │  doc_id: &quot;paper_001&quot;   │
                │  inputs: {paths...}    │  ◄── from storage.py
                │  outputs: {paths...}   │  ◄── from storage.py
                │  params: {values...}   │  ◄── from resources.yaml
                └────────────────────────┘
                             │
                             ▼
                       CPU SCRIPT
                  (reads ONLY from contract)
</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
resources.yaml          contract.py              core.py
      │                      │                      │
      │  (param values)      │  (input/output defs) │
      └──────────────────────┴──────────────────────┘
                             │
                             ▼
                ┌────────────────────────┐
                │     CONTRACT JSON      │
                │  ─────────────────────  │
                │  doc_id: "paper_001"   │
                │  inputs: \textbraceleft{\textbraceright{}paths...\textbraceright{}    │  ◄── from storage.py
                │  outputs: \textbraceleft{\textbraceright{}paths...\textbraceright{}   │  ◄── from storage.py
                │  params: \textbraceleft{\textbraceright{}values...\textbraceright{}   │  ◄── from resources.yaml
                └────────────────────────┘
                             │
                             ▼
                       CPU SCRIPT
                  (reads ONLY from contract)

\end{Verbatim}
~~~




Cardinal Rules:


- ❌ NEVER import `lib/config.py` directly
- ❌ NEVER read `resources.yaml` directly
- ✅ ALL params from `contract["params"]`
- ✅ ALL paths from `contract["inputs"]` / `contract["outputs"]`

### Essential Script Pattern




~~~{=html}
<pre class="notion-ascii-diagram"><code>STAGE_ID = &quot;GX_YY&quot;

def process_item(item):
    &quot;&quot;&quot;Must be picklable - no lambdas, no closures.&quot;&quot;&quot;
    return result

def run_stage(*, doc_id, params, logger, inputs, outputs):
    results = parallel_map(
        items,
        process_item,
        workers=params.get(&quot;workers&quot;, 4),
        stage_id=STAGE_ID,  # ⚠️ CRITICAL - without this, logs show &quot;unknown_stage&quot;
    )
    return {&quot;count&quot;: len(results)}

def main():
    logger = setup_logging(STAGE_ID)
    contract = load_contract_json(Path(args.contract_json))
    inputs = resolve_paths(contract[&quot;inputs&quot;], Path(args.input_dir))
    outputs = resolve_paths(contract[&quot;outputs&quot;], Path(args.output_dir))

    validate_inputs(...)   # Before processing
    ensure_output_dirs(...)
    run_stage(...)
    validate_outputs(...)  # After processing
</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
STAGE_ID = "GX_YY"

def process_item(item):
    """Must be picklable - no lambdas, no closures."""
    return result

def run_stage(*, doc_id, params, logger, inputs, outputs):
    results = parallel_map(
        items,
        process_item,
        workers=params.get("workers", 4),
        stage_id=STAGE_ID,  # ⚠️ CRITICAL - without this, logs show "unknown_stage"
    )
    return \textbraceleft{\textbraceright{}"count": len(results)\textbraceright{}

def main():
    logger = setup_logging(STAGE_ID)
    contract = load_contract_json(Path(args.contract_json))
    inputs = resolve_paths(contract["inputs"], Path(args.input_dir))
    outputs = resolve_paths(contract["outputs"], Path(args.output_dir))

    validate_inputs(...)   # Before processing
    ensure_output_dirs(...)
    run_stage(...)
    validate_outputs(...)  # After processing

\end{Verbatim}
~~~








---


## 2. GPU Stage Architecture


### Flow Diagram




~~~{=html}
<pre class="notion-ascii-diagram"><code>┌─────────────────────────────────────────────────────────────┐
│                    ORCHESTRATOR (core.py)                   │
│                                                             │
│  Creates CONTRACT JSON, calls dispatch script               │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                DISPATCH SCRIPT (GX_YY_dispatch.py)          │
│                                                             │
│  1. Load contract                                           │
│  2. Extract job_queue, sentinel_suffix from params          │
│  3. Publish job to RabbitMQ                                 │
│  4. Wait for sentinel file (blocking)                       │
│  5. Validate outputs, exit                                  │
└─────────────────────────────────────────────────────────────┘
          │                                       ▲
          │ dispatch_job()                        │ sentinel file appears
          ▼                                       │
    ┌───────────┐                                 │
    │ RabbitMQ  │                                 │
    │   Queue   │                                 │
    └───────────┘                                 │
          │                                       │
          │ consume message                       │
          ▼                                       │
┌─────────────────────────────────────────────────────────────┐
│                 WORKER SCRIPT (GX_YY_worker.py)             │
│                        [DAEMON]                             │
│                                                             │
│  STARTUP (once):                                            │
│    • Load ML models (expensive!)                            │
│    • Connect to RabbitMQ                                    │
│                                                             │
│  LOOP (forever):                                            │
│    1. Receive job from queue                                │
│    2. Report progress IMMEDIATELY                           │
│    3. Run inference using pre-loaded models                 │
│    4. Write outputs                                         │
│    5. Write sentinel file ──────────────────────────────────┘
│    6. ACK message
│    7. Clear progress (in finally:)
└─────────────────────────────────────────────────────────────┘
</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
┌─────────────────────────────────────────────────────────────┐
│                    ORCHESTRATOR (core.py)                   │
│                                                             │
│  Creates CONTRACT JSON, calls dispatch script               │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                DISPATCH SCRIPT (GX_YY_dispatch.py)          │
│                                                             │
│  1. Load contract                                           │
│  2. Extract job_queue, sentinel_suffix from params          │
│  3. Publish job to RabbitMQ                                 │
│  4. Wait for sentinel file (blocking)                       │
│  5. Validate outputs, exit                                  │
└─────────────────────────────────────────────────────────────┘
          │                                       ▲
          │ dispatch_job()                        │ sentinel file appears
          ▼                                       │
    ┌───────────┐                                 │
    │ RabbitMQ  │                                 │
    │   Queue   │                                 │
    └───────────┘                                 │
          │                                       │
          │ consume message                       │
          ▼                                       │
┌─────────────────────────────────────────────────────────────┐
│                 WORKER SCRIPT (GX_YY_worker.py)             │
│                        [DAEMON]                             │
│                                                             │
│  STARTUP (once):                                            │
│    • Load ML models (expensive!)                            │
│    • Connect to RabbitMQ                                    │
│                                                             │
│  LOOP (forever):                                            │
│    1. Receive job from queue                                │
│    2. Report progress IMMEDIATELY                           │
│    3. Run inference using pre-loaded models                 │
│    4. Write outputs                                         │
│    5. Write sentinel file ──────────────────────────────────┘
│    6. ACK message
│    7. Clear progress (in finally:)
└─────────────────────────────────────────────────────────────┘

\end{Verbatim}
~~~




### Why This Pattern?




~~~{=html}
<pre class="notion-ascii-diagram"><code>WITHOUT dispatch/worker:
  Doc 1: [====Load Model 45s====][Process 10s]
  Doc 2: [====Load Model 45s====][Process 10s]
  Doc 3: [====Load Model 45s====][Process 10s]
  Total: 165 seconds

WITH dispatch/worker:
  Worker startup: [====Load Model 45s====]
  Doc 1: [Process 10s]
  Doc 2: [Process 10s]
  Doc 3: [Process 10s]
  Total: 75 seconds
</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
WITHOUT dispatch/worker:
  Doc 1: [====Load Model 45s====][Process 10s]
  Doc 2: [====Load Model 45s====][Process 10s]
  Doc 3: [====Load Model 45s====][Process 10s]
  Total: 165 seconds

WITH dispatch/worker:
  Worker startup: [====Load Model 45s====]
  Doc 1: [Process 10s]
  Doc 2: [Process 10s]
  Doc 3: [Process 10s]
  Total: 75 seconds

\end{Verbatim}
~~~




### Critical Matching Requirements


Three places must agree or jobs get lost:





~~~{=html}
<pre class="notion-ascii-diagram"><code>┌─────────────────────────────────────────────────────────────┐
│  resources.yaml                                             │
│  ─────────────────                                          │
│  pipelines:                                                 │
│    GX_YY:                                                   │
│      job_queue: &quot;gx_yy_jobs&quot;  ◄───┐                         │
│      sentinel_suffix: &quot;.done&quot;     │                         │
└───────────────────────────────────│─────────────────────────┘
                                    │
                                    │ MUST MATCH
                                    │
┌───────────────────────────────────│─────────────────────────┐
│  GX_YY_worker.py                  │                         │
│  ───────────────────              │                         │
│  WORKER_NAME = &quot;gx_yy-worker&quot; ◄───│───┐                     │
│  JOB_QUEUE = &quot;gx_yy_jobs&quot;  ◄──────┘   │                     │
└───────────────────────────────────────│─────────────────────┘
                                        │
                                        │ MUST MATCH
                                        │
┌───────────────────────────────────────│─────────────────────┐
│  docker-compose.yaml                  │                     │
│  ───────────────────                  │                     │
│  gx-yy-worker:                        │                     │
│    container_name: gx_yy-worker  ◄────┘                     │
│    entrypoint: [&quot;python3&quot;, &quot;GX_YY_worker.py&quot;]               │
└─────────────────────────────────────────────────────────────┘
</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
┌─────────────────────────────────────────────────────────────┐
│  resources.yaml                                             │
│  ─────────────────                                          │
│  pipelines:                                                 │
│    GX_YY:                                                   │
│      job_queue: "gx_yy_jobs"  ◄───┐                         │
│      sentinel_suffix: ".done"     │                         │
└───────────────────────────────────│─────────────────────────┘
                                    │
                                    │ MUST MATCH
                                    │
┌───────────────────────────────────│─────────────────────────┐
│  GX_YY_worker.py                  │                         │
│  ───────────────────              │                         │
│  WORKER_NAME = "gx_yy-worker" ◄───│───┐                     │
│  JOB_QUEUE = "gx_yy_jobs"  ◄──────┘   │                     │
└───────────────────────────────────────│─────────────────────┘
                                        │
                                        │ MUST MATCH
                                        │
┌───────────────────────────────────────│─────────────────────┐
│  docker-compose.yaml                  │                     │
│  ───────────────────                  │                     │
│  gx-yy-worker:                        │                     │
│    container_name: gx_yy-worker  ◄────┘                     │
│    entrypoint: ["python3", "GX_YY_worker.py"]               │
└─────────────────────────────────────────────────────────────┘

\end{Verbatim}
~~~




### Progress Tracking (Workers Only)


Workers must report activity or they appear "Idle" in the monitor:





~~~python
def process_job(doc_id, contract, logger):
    # FIRST LINE - report immediately!
    write_worker_progress(WORKER_NAME, doc_id, 0, "Starting...")

    write_worker_progress(WORKER_NAME, doc_id, 0, "Loading 18 images")
    images = load_images(...)

    write_worker_progress(WORKER_NAME, doc_id, 0, "Running inference")
    results = model.process(images)

    write_outputs(...)
    write_sentinel(...)

def handle_message(ch, method, properties, body, logger):
    try:
        process_job(...)
        ch.basic_ack(...)
    finally:
        clear_worker_progress(WORKER_NAME)  # ALWAYS in finally!

~~~















