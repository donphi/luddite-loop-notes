# my notes


## Content


stage0 - index corpus as is, paragraph text header, abstract,  table headings and left hand column

stage1 - index features and lemmentize feature titles - removes plural, removes stopword and matches phrases like 



do we add:






~~~javascript
# In index_mapping.settings.analysis.analyzer, add:
text_analyzer_stemmed:
  type: "custom"
  tokenizer: "standard"
  filter: ["lowercase", "porter_stem"]

# In index_mapping.mappings.properties, add:
text_stemmed:
  type: "text"
  analyzer: "text_analyzer_stemmed"
~~~






~~~{=html}
<pre class="notion-ascii-diagram"><code>╔══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗
║                                            OPTIONS FOR IMPROVEMENT                                                                ║
╠══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣
║                                                                                                                                   ║
║  OPTION A: KEEP AS-IS ✅ (Recommended for now)                                                                                    ║
║  ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── ║
║                                                                                                                                   ║
║  The current approach is reasonable:                                                                                              ║
║    • Multiple alias variants catch different phrasings                                                                            ║
║    • Already tested and tuned over 3 weeks (per the code comments)                                                                ║
║    • No risk of introducing false matches from aggressive stemming                                                                ║
║                                                                                                                                   ║
║  Verdict: Works well enough. Don&#39;t fix what isn&#39;t broken.                                                                         ║
║                                                                                                                                   ║
║  ═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════ ║
║                                                                                                                                   ║
║  OPTION B: ADD STEMMED FIELD (Minimal change, optional enhancement)                                                               ║
║  ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── ║
║                                                                                                                                   ║
║  Add a text_stemmed field alongside text_lower:                                                                                   ║
║                                                                                                                                   ║
║    • Stage 2 could optionally search text_stemmed for fuzzy matching                                                              ║
║    • Keep text_lower for exact phrase matching (current behavior)                                                                 ║
║    • Best of both worlds: choose per-query                                                                                        ║
║                                                                                                                                   ║
║  Effort: ~10 lines changed                                                                                                        ║
║  Risk: Low (additive, doesn&#39;t break existing)                                                                                     ║
║  Benefit: Catches &quot;smoked&quot; → &quot;smoke&quot; variants                                                                                     ║
║                                                                                                                                   ║
╚══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
╔══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗
║                                            OPTIONS FOR IMPROVEMENT                                                                ║
╠══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣
║                                                                                                                                   ║
║  OPTION A: KEEP AS-IS ✅ (Recommended for now)                                                                                    ║
║  ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── ║
║                                                                                                                                   ║
║  The current approach is reasonable:                                                                                              ║
║    • Multiple alias variants catch different phrasings                                                                            ║
║    • Already tested and tuned over 3 weeks (per the code comments)                                                                ║
║    • No risk of introducing false matches from aggressive stemming                                                                ║
║                                                                                                                                   ║
║  Verdict: Works well enough. Don't fix what isn't broken.                                                                         ║
║                                                                                                                                   ║
║  ═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════ ║
║                                                                                                                                   ║
║  OPTION B: ADD STEMMED FIELD (Minimal change, optional enhancement)                                                               ║
║  ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── ║
║                                                                                                                                   ║
║  Add a text_stemmed field alongside text_lower:                                                                                   ║
║                                                                                                                                   ║
║    • Stage 2 could optionally search text_stemmed for fuzzy matching                                                              ║
║    • Keep text_lower for exact phrase matching (current behavior)                                                                 ║
║    • Best of both worlds: choose per-query                                                                                        ║
║                                                                                                                                   ║
║  Effort: ~10 lines changed                                                                                                        ║
║  Risk: Low (additive, doesn't break existing)                                                                                     ║
║  Benefit: Catches "smoked" → "smoke" variants                                                                                     ║
║                                                                                                                                   ║
╚══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝
\end{Verbatim}
~~~





quality gate:





ES returns aggregated counts by source_type:
body:              45,000 hits
abstract:           3,000 hits



table_header:       8,000 hits
table_row_header:   2,000 hits
...



We compute:
text_hits  = 45000 + 3000 + 500 + 200 = 48,700  (body + abstract + title + section_header + caption)
table_hits = 8000 + 2000 + 5000 = 15,000        (table_header + table_row_header + table_data_cell)
doc_count  = unique docs containing "bmi" = 12,000



counts = (48700, 15000, 12000)



STEP 3: Apply is_clean_alias() (01_mine_aliases.py:369 → lib/alias_utils.py:241)







now lets say BMI

Gate 1:
table artifact

Gate 2: length




