# Results and Assessment


## Content


## 1. Objective and Scope of the Preliminary Evaluation


The objective of this preliminary evaluation, based on the pre-workup of 23 experiments completed, see 1.ðŸ”¬ Evaluation Breakdown was used to determine whether large-scale feature extraction from UK Biobank research papers would yield any meaningful pattern, specifically whether a stable â€œcoreâ€ set of features exists across studies.







This was not a deterministic or production-level workflow. This was a prototype feasibility evaluation executed with:


- opportunistically cleaned PDFs,
- non-standardised extraction outputs,
- imperfect metadata alignment,
- simple NLP + pattern matching,
- initial bootstrapping statistics.





This evaluation aimed to assess the following:


1. **Should a full, deterministic, multi-model pipeline be built?**
2. **Was there any evidence that such work would yield a high-value scientific structure for an MSc in Artificial Intelligence and Digital Health?**





### 1.1 Hypothesis Framework


This preliminary analysis was designed to test a focused scientific hypothesis derived from the UK Biobankâ€™s open-access research corpus.



### **Primary Research Question**


Do UK Biobank research papers published in open-source journals exhibit a stable, cross-domain core set of features, or is feature usage fragmented and domain specific?stable, cross-domain core set of features



### **Hypotheses**

- **Hâ‚€ (Null Hypothesis):**

    Feature usage in UK Biobank studies is heterogeneous and fragmented. No statistically stable core feature sets exist across the different disease domains.
    

- **Hâ‚ (Alternative Hypothesis):**

    A statistically significant core-periphery structure exists in UK Biobank researchcore-periphery structure
    

    - a small, highly recurrent _core_ of features used across nearly all studies
    - a larger, domain-specific _periphery_ of rarely used features

    



To support readers from life-sciences disciplines, it is important to emphasise that feature selection is not merely a machine learning concern: in outcome-based UK Biobank research, the emergence of a stable, repeatedly used core of features may signal a narrowing of analytic focus across the literature, rather than the methodological diversity the resource was originally created to enable. This framing explains why the hypothesis explicitly evaluates feature stability rather than treating feature choice as an incidental.







### **1.2 Purpose of Preliminary Evaluation**


This preliminary evaluation was not intended to produce final scientific conclusions.



Its purpose was to determine the following:


1. **Does the UK Biobank research corpus contain sufficient signal to justify building a deterministic, industrial-strength pipeline?**
2. **Is there evidence of a discoverable core set of features using even brittle extraction methods**
3. **If the core-periphery structure holds under noisy conditions, is it worth pursuing a fully GPU-accelerated, multi-model, ontology-driven pipeline?**

Therefore, the hypothesis is tightly coupled to the engineering roadmap.



If even a noisy pipeline detects a core structure, then a deterministic system is scientifically valuable.







---






## 2. Methods and Process Summary


The process followed a simplified experimental workflow, as described in the 1.ðŸ”¬ Evaluation Breakdown






1. **PDF Acquisition & Cleaning**

    Large corpus of open-access UK Biobank studies. Retrieval and cleaning were ad hoc and inconsistent.
    

2. **Markdown/JSON Conversion (Non-deterministic)**

    Early stage PDF â†’ MD/JSON conversion with imperfect extractions. No validation process was considered, and no source of truth â€œspineâ€ was created for each process to latch onto.source of truth â€œspineâ€
    

3. **Feature Extraction (Prototype)**
    - heuristic term matching
    - synonym expansion via simple dictionaries
    - approximate field resolution
4. **Statistical Testing**
    - Basic bootstrap resampling (n = 1,000)
    - Jaccard similarity
    - Gini coefficient
    - Feature coverage curves
5. **Interpretation**

    Evaluation of whether stable patterns emerged despite the noise and fragility of the processes.despite
    






Because this pipeline was deliberately minimal, the results represent a lower bound on the true signal quality.a lower bound







---






## 3. Key Findings and Technical Outcomes


### **3.1 Strong Evidence of a Stable Core Feature Set**


Even under brittle extraction conditions:


- **Jaccard core stability = 0.970**
- **95% CI = [0.905, 1.000]**
- **Top-50 features cover ~96.6% of papers**
- **Gini coefficient = 0.866** (extreme concentration)

This indicates a clear and reproducible core-periphery structure across UK Biobank research.clear, reproducible core-periphery structure







### **3.2 Early Pipeline Noise Did Not Destroy the Signal**


Despite the inconsistent PDFs, imperfect parsing, and suboptimal alignment, the same features were dominant.



This strongly suggests that a more accurate deterministic extraction pipeline will yield an even cleaner structure.







### **3.3 Feature Space is Imbalanced but Meaningful**


A total of 3,725 distinct features were detected, but a small minority dominated.


- **Top 20 features â†’ >90% coverage**
- **Top 50 features â†’ >96% coverage**

This concentration validates that the large-scale feature analysis is computationally tractable.







### **3.4 Clear Incentive to Build the Deterministic Pipeline**


The exploratory results justify the following:


- developing a stable token spine from the start,
- building a structured, multi-pipeline system,
- enforcing model redundancy,
- validate each incremental step within each pipeline,
- implementing ontology-driven normalisation and tagging,





The preliminary findings demonstrate that the research problem has a strong underlying structure and that a major pipeline is necessary to unlock its full scientific value.the research problem has strong underlying structure







---






## 4. Critical Reflection


This preliminary evaluation was intentionally fragile for fast and iterative learning. The key limitations are as follows:


1. **Extraction Noise**

    Poorly structured PDFs cause mis-tagging, truncated content, and inconsistent feature boundaries.
    

2. **No Canonical Token Spine**

    Without ALTO XML or deterministic text alignment, the entity boundaries were unstable.
    

3. **Weak Normalisation**

    Basic heuristics led to over-inflated feature counts and the merging of non-equivalent terms.
    

4. **Limited Validation**

    No multi-model redundancy, no three-witness system, and no structured Quality Checks.Quality Checks
    

5. **Statistical Interpretation Bound by Noise**

    The results cannot be considered scientifically accurate, only directionally meaningful.
    


    



Despite these limitations, the core-periphery signal survived, demonstrating that the phenomenon is real enough to justify the construction of an advanced, reproducible extraction pipeline.core-periphery signal survived






























