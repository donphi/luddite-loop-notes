# NER Disease Normalisation


## Content


# Disease Normalization with SapBERT + FAISS

> Mapping raw disease mentions ("Alzheimer's", "AD", "senile dementia") to standardized UMLS concept identifiers.

---


## How It Works




~~~{=html}
<pre class="notion-ascii-diagram"><code>┌─────────────────────────────────────────────────────────────────────────────┐
│                                                                             │
│  &quot;Alzheimer&#39;s&quot;  ──►  SapBERT  ──►  768-dim vector  ──►  FAISS  ──►  CUI     │
│                      Encoder       [CLS] embedding      Search              │
│                                                                             │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│    <strong>Step 1             Step 2            Step 3             Step 4     </strong>      │
│   ┌────────────┐     ┌────────────┐     ┌────────────┐     ┌────────────┐   │
│   │ <strong>Tokenize</strong>   │     │ <strong>BERT </strong>      │     │ <strong>Extract </strong>   │     │ <strong>Find</strong>       │   │
│   │ + pad to   │ ──► │ forward    │ ──► │ [CLS]      │ ──► │ nearest    │   │
│   │ 25 tokens  │     │ pass       │     │ token      │     │ neighbor   │   │
│   └────────────┘     └────────────┘     └────────────┘     └────────────┘   │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
┌─────────────────────────────────────────────────────────────────────────────┐
│                                                                             │
│  "Alzheimer's"  ──►  SapBERT  ──►  768-dim vector  ──►  FAISS  ──►  CUI     │
│                      Encoder       [CLS] embedding      Search              │
│                                                                             │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│    \textbf{Step 1             Step 2            Step 3             Step 4     }      │
│   ┌────────────┐     ┌────────────┐     ┌────────────┐     ┌────────────┐   │
│   │ \textbf{Tokenize}   │     │ \textbf{BERT }      │     │ \textbf{Extract }   │     │ \textbf{Find}       │   │
│   │ + pad to   │ ──► │ forward    │ ──► │ [CLS]      │ ──► │ nearest    │   │
│   │ 25 tokens  │     │ pass       │     │ token      │     │ neighbor   │   │
│   └────────────┘     └────────────┘     └────────────┘     └────────────┘   │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
\end{Verbatim}
~~~




Core idea: SapBERT learns that synonyms should have similar embeddings. "Myocardial infarction" and "heart attack" map to nearby points in 768-dimensional space because they share the same UMLS concept.



---


## Model Specification



<table>
  <thead>
    <tr>
      <th>Parameter</th>
      <th>Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Model</strong></td>
      <td><code>dmis-lab/biosyn-sapbert-bc5cdr-disease</code></td>
    </tr>
    <tr>
      <td><strong>Base</strong></td>
      <td>PubMedBERT (pre-trained on PubMed abstracts)</td>
    </tr>
    <tr>
      <td><strong>Embedding dimension</strong></td>
      <td>768</td>
    </tr>
    <tr>
      <td><strong>Max sequence length</strong></td>
      <td>25 tokens</td>
    </tr>
    <tr>
      <td><strong>Training method</strong></td>
      <td>Self-Alignment Pre-training on UMLS synonym pairs</td>
    </tr>
  </tbody>
</table>



---


## FAISS Index Structure


The dictionary contains 141,479 UMLS disease concepts, each pre-embedded as a 768-dim vector.





~~~{=html}
<pre class="notion-ascii-diagram"><code>┌─────────────────────────────────────────────────────────────────────┐
│                 <strong>141,479 CONCEPT EMBEDDINGS (NER Tags)   </strong>            │
│                    partitioned into 2,048 clusters                  │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│ <strong>  Cluster 1       Cluster 2       Cluster 3   ...   Cluster 2048    │</strong>
│   ┌─────────┐    ┌─────────┐    ┌─────────┐         ┌─────────┐     │
│   │ ● C001  │    │ ● C089  │    │ ● C156  │         │ ● C999  │     │
│   │ ● C012  │    │ ● C102  │    │ ● C178  │   ...   │ ● C1001 │     │
│   │ ● C034  │    │ ● C145  │    │ ● C201  │         │ ● C1089 │     │
│   └─────────┘    └─────────┘    └─────────┘         └─────────┘     │
│                                                                     │
│   <strong>Query:</strong> &quot;dementia&quot;                                                 │
│   1. Find 25 nearest cluster centroids                              │
│   2. Exhaustively search within those clusters                      │
│   3. Return top-1 by cosine similarity                              │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
┌─────────────────────────────────────────────────────────────────────┐
│                 \textbf{141,479 CONCEPT EMBEDDINGS (NER Tags)   }            │
│                    partitioned into 2,048 clusters                  │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│ \textbf{  Cluster 1       Cluster 2       Cluster 3   ...   Cluster 2048    │}
│   ┌─────────┐    ┌─────────┐    ┌─────────┐         ┌─────────┐     │
│   │ ● C001  │    │ ● C089  │    │ ● C156  │         │ ● C999  │     │
│   │ ● C012  │    │ ● C102  │    │ ● C178  │   ...   │ ● C1001 │     │
│   │ ● C034  │    │ ● C145  │    │ ● C201  │         │ ● C1089 │     │
│   └─────────┘    └─────────┘    └─────────┘         └─────────┘     │
│                                                                     │
│   \textbf{Query:} "dementia"                                                 │
│   1. Find 25 nearest cluster centroids                              │
│   2. Exhaustively search within those clusters                      │
│   3. Return top-1 by cosine similarity                              │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘

\end{Verbatim}
~~~





<table>
  <thead>
    <tr>
      <th><strong>Parameter</strong></th>
      <th><strong>Value</strong></th>
      <th><strong>Purpose</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Index type</strong></td>
      <td>IVFFlat</td>
      <td>Inverted file with exact inner search</td>
    </tr>
    <tr>
      <td><strong>Clusters (nlist)</strong></td>
      <td>2,048</td>
      <td>Voronoi partitioning of embedding space</td>
    </tr>
    <tr>
      <td><strong>Clusters searched (nprobe)</strong></td>
      <td>25</td>
      <td>Speed vs accuracy tradeoff</td>
    </tr>
    <tr>
      <td><strong>Metric</strong></td>
      <td>Inner product</td>
      <td>Equivalent to cosine for normalized vectors</td>
    </tr>
    <tr>
      <td><strong>Dictionary size</strong></td>
      <td>141,479</td>
      <td>UMLS disease concepts</td>
    </tr>
  </tbody>
</table>



---


## Similarity Metric


When vectors are L2-normalized (unit length), inner product equals cosine similarity:





~~~{=html}
<pre class="notion-ascii-diagram"><code>sim(query, concept) = query · concept = cos(θ)

    where ||query|| = ||concept|| = 1</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
sim(query, concept) = query · concept = cos(θ)

    where ||query|| = ||concept|| = 1
\end{Verbatim}
~~~





<table>
  <thead>
    <tr>
      <th>Score</th>
      <th>Interpretation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1.0</td>
      <td>Identical meaning</td>
    </tr>
    <tr>
      <td>0.8+</td>
      <td>Strong match</td>
    </tr>
    <tr>
      <td>0.5–0.8</td>
      <td>Moderate similarity</td>
    </tr>
    <tr>
      <td>&lt;0.5</td>
      <td>Weak match</td>
    </tr>
  </tbody>
</table>



No threshold applied — the system returns the top-1 match unconditionally. (uneven; always an answer)



---


## Ambiguity Detection


Short uppercase acronyms produce unreliable embeddings:


- Limited lexical signal (2–3 characters)
- Multiple valid expansions ("AD" = Alzheimer's Disease OR Atopic Dermatitis)
- SapBERT cannot disambiguate without context



~~~{=html}
<pre class="notion-ascii-diagram"><code>┌────────────────────────────────────────────────────────────────┐
│                  <strong>  AMBIGUITY DECISION TREE   </strong>                  │
├────────────────────────────────────────────────────────────────┤
│                                                                │
│   Input: &quot;AD&quot;                                                  │
│      │                                                         │
│      ▼                                                         │
│   In allowlist? ──► NO                                         │
│      │                                                         │
│      ▼                                                         │
│   In denylist? ──► YES ──► Mark as CUI-less                    │
│                                                                │
│   ─────────────────────────────────────────────────────────    │
│                                                                │
│   Input: &quot;Alzheimer&#39;s disease&quot;                                 │
│      │                                                         │
│      ▼                                                         │
│   In allowlist? ──► NO                                         │
│      │                                                         │
│      ▼                                                         │
│   In denylist? ──► NO                                          │
│      │                                                         │
│      ▼                                                         │
│   Length &gt; 3? ──► YES ──► Normalize with SapBERT               │
│                                                                │
└────────────────────────────────────────────────────────────────┘
</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
┌────────────────────────────────────────────────────────────────┐
│                  \textbf{  AMBIGUITY DECISION TREE   }                  │
├────────────────────────────────────────────────────────────────┤
│                                                                │
│   Input: "AD"                                                  │
│      │                                                         │
│      ▼                                                         │
│   In allowlist? ──► NO                                         │
│      │                                                         │
│      ▼                                                         │
│   In denylist? ──► YES ──► Mark as CUI-less                    │
│                                                                │
│   ─────────────────────────────────────────────────────────    │
│                                                                │
│   Input: "Alzheimer's disease"                                 │
│      │                                                         │
│      ▼                                                         │
│   In allowlist? ──► NO                                         │
│      │                                                         │
│      ▼                                                         │
│   In denylist? ──► NO                                          │
│      │                                                         │
│      ▼                                                         │
│   Length > 3? ──► YES ──► Normalize with SapBERT               │
│                                                                │
└────────────────────────────────────────────────────────────────┘

\end{Verbatim}
~~~





<table>
  <thead>
    <tr>
      <th><strong>Config</strong></th>
      <th><strong>Value</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Pattern</strong></td>
      <td><code>^[A-Z]{1,3}$</code> (1–3 uppercase letters)</td>
    </tr>
    <tr>
      <td><strong>Max length</strong></td>
      <td>3 characters</td>
    </tr>
    <tr>
      <td><strong>Denylist</strong></td>
      <td>AD, ADD, MS, PD, AF, AMD, ALL, AML</td>
    </tr>
    <tr>
      <td><strong>Action</strong></td>
      <td>Mark as &quot;CUI-less&quot;</td>
    </tr>
  </tbody>
</table>



---


## Processing Pipeline




~~~{=html}
<pre class="notion-ascii-diagram"><code><strong>STEP 1: LOAD</strong>
        2,545 parquet files → 1,272,500 disease mentions

<strong>STEP 2: DEDUPLICATE</strong>
        1,272,500 mentions → 64,797 unique text spans (19.6× reduction)

<strong>STEP 3: FILTER AMBIGUOUS</strong>
        64,797 spans → 1,772 flagged as ambiguous acronyms

<strong>STEP 4: ENCODE (GPU)</strong>
        63,025 spans → SapBERT → 768-dim embeddings
        Batch size: 16,384 | ~12 seconds

<strong>STEP 5: SEARCH</strong>
        FAISS index → top-1 CUI per span

<strong>STEP 6: WRITE BACK</strong>
        Map CUIs back to 1,270,728 original mentions
        Mark 1,772 ambiguous as CUI-less
</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
\textbf{STEP 1: LOAD}
        2,545 parquet files → 1,272,500 disease mentions

\textbf{STEP 2: DEDUPLICATE}
        1,272,500 mentions → 64,797 unique text spans (19.6× reduction)

\textbf{STEP 3: FILTER AMBIGUOUS}
        64,797 spans → 1,772 flagged as ambiguous acronyms

\textbf{STEP 4: ENCODE (GPU)}
        63,025 spans → SapBERT → 768-dim embeddings
        Batch size: 16,384 | ~12 seconds

\textbf{STEP 5: SEARCH}
        FAISS index → top-1 CUI per span

\textbf{STEP 6: WRITE BACK}
        Map CUIs back to 1,270,728 original mentions
        Mark 1,772 ambiguous as CUI-less

\end{Verbatim}
~~~




---


## Results



<table>
  <thead>
    <tr>
      <th><strong>Category</strong></th>
      <th><strong>Count</strong></th>
      <th><strong>%</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Total mentions</td>
      <td>1,272,500</td>
      <td>100.0</td>
    </tr>
    <tr>
      <td>Unique text spans</td>
      <td>64,797</td>
      <td>—</td>
    </tr>
    <tr>
      <td>Successfully normalized</td>
      <td>63,025</td>
      <td>97.3</td>
    </tr>
    <tr>
      <td>Marked CUI-less (ambiguous)</td>
      <td>1,772</td>
      <td>2.7</td>
    </tr>
    <tr>
      <td><strong>Failed normalization</strong></td>
      <td>0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>



---


## Computational Profile



<table>
  <thead>
    <tr>
      <th>Resource</th>
      <th>Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>GPU</strong></td>
      <td>NVIDIA RTX 6000 Pro (96GB VRAM)</td>
    </tr>
    <tr>
      <td><strong>Model memory</strong></td>
      <td>~438 MB</td>
    </tr>
    <tr>
      <td><strong>Index memory</strong></td>
      <td>~820 MB</td>
    </tr>
    <tr>
      <td><strong>Total time</strong></td>
      <td>~30 seconds for 64,797 spans</td>
    </tr>
    <tr>
      <td><strong>Throughput</strong></td>
      <td>~2,160 spans/second</td>
    </tr>
  </tbody>
</table>



---


## Configuration (resources.yaml)




~~~{=html}
<pre class="notion-ascii-diagram"><code>Yaml

disease_normalization:
  sapbert_model: &quot;dmis-lab/biosyn-sapbert-bc5cdr-disease&quot;
  cache_path: &quot;/app/models/bern2_normalization/neural_cache/dict_Disease.pk&quot;
  device: &quot;gpu&quot;
  batch_size: 16384
  max_length: 25
  top_k: 1
  no_entity_id: &quot;CUI-less&quot;
</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
Yaml

disease_normalization:
  sapbert_model: "dmis-lab/biosyn-sapbert-bc5cdr-disease"
  cache_path: "/app/models/bern2_normalization/neural_cache/dict_Disease.pk"
  device: "gpu"
  batch_size: 16384
  max_length: 25
  top_k: 1
  no_entity_id: "CUI-less"

\end{Verbatim}
~~~




---


## Limitations



<table>
  <thead>
    <tr>
      <th><strong>Issue</strong></th>
      <th><strong>Impact</strong></th>
      <th><strong>Mitigation</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>No confidence threshold</td>
      <td>All top-1 matches accepted</td>
      <td>Assume nearest neighbor is correct</td>
    </tr>
    <tr>
      <td>Context-free</td>
      <td>&quot;AD&quot; cannot be disambiguated</td>
      <td>Ambiguity detection → CUI-less</td>
    </tr>
    <tr>
      <td>Dictionary coverage</td>
      <td>Rare diseases may miss</td>
      <td>UMLS 2021 has 141K concepts</td>
    </tr>
    <tr>
      <td>Synonym overlap</td>
      <td>Similar CUIs compete</td>
      <td>Accept some error at boundaries</td>
    </tr>
  </tbody>
</table>



---


UMLS dictionary version: 2021-06-30 | SapBERT fine-tuned on BC5CDR disease corpus






