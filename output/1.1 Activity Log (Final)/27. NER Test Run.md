# NER Test Run


## Content


## 1. Objective and Scope


### 1.1 Problem Statement


Disease ranking outputs exhibited systematic failures including:


- Incorrect source attribution (title entities appearing as abstract-sourced)
- Catastrophic normalization errors (e.g., "Alzheimer's Disease" → "Attention Deficit Disorder")
- Orphan rankings for documents missing from extraction tables

### 1.2 Hypothesis


Title and abstract extraction coverage was compromised due to:


1. Multi-tag filtering dropping valid lines (lines with both `title` + `section_header` tags)
2. Metadata-only extraction missing OCR-tagged content
3. Witness models (GLiNER, PubMedBERT-NER) not dispatching

### 1.3 Scope


Audit the complete NER pipeline from paper.json ingestion through disease mention extraction to verify:


- Zone coverage across all extraction sources
- Multi-model dispatch integrity
- Source data quality in upstream paper.json files

---


## 2. Methods and Process


### 2.1 Pipeline Architecture




~~~{=html}
<pre class="notion-ascii-diagram"><code>┌─────────────────────────────────────────────────────────────────────────────────┐
│                <strong>           NER EXTRACTION PIPELINE      </strong>                         │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
<strong>│  paper.json ──► Dispatcher ──► RabbitMQ  ──►  Model Workers ──► Results Writer  │</strong>
│        │                          │                │                   │        │
│        │                          └───────┬────────┘                   │        │
│        │                             ┌────┘                            │        │ 
│        │             ┌───────────────┼───────────────┐               ┌─┘        │
│        │             │               │               │               │          │
│        ▼             ▼               ▼               ▼               ▼          │
│  ┌────────────┐   ┌─────────┐   ┌──────────┐   ┌──────────┐     ┌─────────┐     │
│  │  <strong> Zones    │   │  BERN2  │   │  GLiNER  │   │PubMedBERT│     │ Parquet │     │</strong>
│  │ title,abs, │   │  (NER)  │   │ (witness)│   │ (witness)│     │ Output  │     │
│  │ meta,blocs │   └─────────┘   └──────────┘   └──────────┘     └─────────┘     │
│  └────────────┘                                                                 │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
┌─────────────────────────────────────────────────────────────────────────────────┐
│                \textbf{           NER EXTRACTION PIPELINE      }                         │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
\textbf{│  paper.json ──► Dispatcher ──► RabbitMQ  ──►  Model Workers ──► Results Writer  │}
│        │                          │                │                   │        │
│        │                          └───────┬────────┘                   │        │
│        │                             ┌────┘                            │        │ 
│        │             ┌───────────────┼───────────────┐               ┌─┘        │
│        │             │               │               │               │          │
│        ▼             ▼               ▼               ▼               ▼          │
│  ┌────────────┐   ┌─────────┐   ┌──────────┐   ┌──────────┐     ┌─────────┐     │
│  │  \textbf{ Zones    │   │  BERN2  │   │  GLiNER  │   │PubMedBERT│     │ Parquet │     │}
│  │ title,abs, │   │  (NER)  │   │ (witness)│   │ (witness)│     │ Output  │     │
│  │ meta,blocs │   └─────────┘   └──────────┘   └──────────┘     └─────────┘     │
│  └────────────┘                                                                 │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘

\end{Verbatim}
~~~




### 2.2 Extraction Zones Evaluated



<table>
  <thead>
    <tr>
      <th>Zone <strong>Name</strong></th>
      <th><strong>Source</strong></th>
      <th><strong>Filter</strong></th>
      <th><strong>Purpose</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>title_lines</code></td>
      <td><code>lines[]</code></td>
      <td><code>tags_include: [title]</code>, <code>match_mode: canonical</code></td>
      <td>OCR-tagged title lines</td>
    </tr>
    <tr>
      <td><code>abstract_lines</code></td>
      <td><code>lines[]</code></td>
      <td><code>tags_include: [abstract]</code>, <code>match_mode: canonical</code></td>
      <td>OCR-tagged abstract lines</td>
    </tr>
    <tr>
      <td><code>metadata_title</code></td>
      <td><code>metadata.title</code></td>
      <td>—</td>
      <td>GROBID-structured title</td>
    </tr>
    <tr>
      <td><code>metadata_abstract</code></td>
      <td><code>metadata.abstract</code></td>
      <td>—</td>
      <td>GROBID-structured abstract</td>
    </tr>
    <tr>
      <td><code>abstract_blocks</code></td>
      <td><code>blocks[]</code></td>
      <td><code>canonical_type: abstract</code></td>
      <td>Retrieval substrate fallback</td>
    </tr>
  </tbody>
</table>



### 2.3 Diagnostic Approach

1. **Parquet inspection**: Query extraction_units and disease_mentions tables
2. **Paper.json sampling**: Inspect 5+ documents reporting `abs_lines=0`
3. **Tag structure analysis**: Enumerate all tags present in source lines
4. **Content verification**: Confirm presence/absence of abstract text in source

---


## 3. Key Findings and Technical Outcomes


### 3.1 Extraction Coverage Summary



<table>
  <thead>
    <tr>
      <th><strong>Metric</strong></th>
      <th><strong>Count</strong></th>
      <th><strong>Percentage</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Total papers processed</td>
      <td>6,589</td>
      <td>100%</td>
    </tr>
    <tr>
      <td>Papers with extraction units</td>
      <td>6,582</td>
      <td>99.9%</td>
    </tr>
    <tr>
      <td>Papers with 0 extraction units</td>
      <td>7</td>
      <td>0.1%</td>
    </tr>
    <tr>
      <td>Papers with disease mentions</td>
      <td>6,511</td>
      <td>98.8%</td>
    </tr>
    <tr>
      <td>Papers without disease mentions</td>
      <td>78</td>
      <td>1.2%</td>
    </tr>
  </tbody>
</table>



### 3.2 Abstract Source Coverage



<table>
  <thead>
    <tr>
      <th><strong>Category</strong></th>
      <th><strong>Count</strong></th>
      <th><strong>Notes</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Papers with ANY abstract source</td>
      <td>6,388</td>
      <td>abstract_lines OR abstract_blocks OR metadata_abstract</td>
    </tr>
    <tr>
      <td>Papers with NO abstract source</td>
      <td>201</td>
      <td>Source paper.json contains no abstract content</td>
    </tr>
    <tr>
      <td>Papers with NO title source</td>
      <td>23</td>
      <td>Missing title in source</td>
    </tr>
    <tr>
      <td>Papers with NEITHER</td>
      <td>7</td>
      <td>Broken <code>reading_order</code> (upstream failure)</td>
    </tr>
  </tbody>
</table>



### 3.3 Zone-Level Extraction Statistics




~~~{=html}
<pre class="notion-ascii-diagram"><code><strong>Zone                         Units Created    Docs Covered    Disease Mentions</strong>
────────────────────────────────────────────────────────────────────────────────
abstract_lines                    187,855          6,361            795,019
title_lines                        54,196          6,566             66,991
abstract_blocks                    14,042          6,361            219,999
metadata_title                      6,541          6,541             22,530
metadata_abstract                   6,234          6,234            167,961
────────────────────────────────────────────────────────────────────────────────
<strong>TOTAL                             268,868              —          1,272,500</strong></code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
\textbf{Zone                         Units Created    Docs Covered    Disease Mentions}
────────────────────────────────────────────────────────────────────────────────
abstract_lines                    187,855          6,361            795,019
title_lines                        54,196          6,566             66,991
abstract_blocks                    14,042          6,361            219,999
metadata_title                      6,541          6,541             22,530
metadata_abstract                   6,234          6,234            167,961
────────────────────────────────────────────────────────────────────────────────
\textbf{TOTAL                             268,868              —          1,272,500}
\end{Verbatim}
~~~




### 3.4 Model Dispatch Verification


All three NER models successfully dispatched and processed:





~~~{=html}
<pre class="notion-ascii-diagram"><code>┌─────────────────────────────────────────────────────────────────┐
│                    <strong>  MODEL QUEUE STATUS   </strong>                      │
├─────────────────────────────────────────────────────────────────┤
│ <strong> Queue                  Final State    Workers    Messages </strong>     │
│  ───────────────────────────────────────────────────────────    │
│  ner.bern2              ✓ EMPTY        3          0             │
│  ner.gliner             ✓ EMPTY        3          0             │
│  ner.pubmedbert_ner     ✓ EMPTY        3          0             │
│  ner.results            ✓ EMPTY        1          0             │
└─────────────────────────────────────────────────────────────────┘</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
┌─────────────────────────────────────────────────────────────────┐
│                    \textbf{  MODEL QUEUE STATUS   }                      │
├─────────────────────────────────────────────────────────────────┤
│ \textbf{ Queue                  Final State    Workers    Messages }     │
│  ───────────────────────────────────────────────────────────    │
│  ner.bern2              ✓ EMPTY        3          0             │
│  ner.gliner             ✓ EMPTY        3          0             │
│  ner.pubmedbert_ner     ✓ EMPTY        3          0             │
│  ner.results            ✓ EMPTY        1          0             │
└─────────────────────────────────────────────────────────────────┘
\end{Verbatim}
~~~




### 3.5 Root Cause Analysis: Papers Without Disease Mentions


The 78 papers without disease mentions decompose as follows:





~~~{=html}
<pre class="notion-ascii-diagram"><code><strong>Papers without disease mentions (n=78)</strong>
│
├── <strong>Papers with 0 extraction units:</strong> 7
│   └── <strong>Cause:</strong> Broken reading_order.page_orders in paper.json
│
└── <strong>Papers with extraction units but 0 diseases:</strong> 71
    └── <strong>Cause:</strong> Paper title content does not contain disease terms
        <strong>Examples:</strong>
        ├── &quot;A Robust Example of Collider Bias in a Genetic Association Study&quot;
        ├── &quot;Genetic variants linked to education predict longevity&quot;
        ├── &quot;BGData - A Suite of R Packages for Genomic Analysis&quot;
        └── &quot;Efficient haplotype matching between a query and a panel&quot;</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
\textbf{Papers without disease mentions (n=78)}
│
├── \textbf{Papers with 0 extraction units:} 7
│   └── \textbf{Cause:} Broken reading_order.page_orders in paper.json
│
└── \textbf{Papers with extraction units but 0 diseases:} 71
    └── \textbf{Cause:} Paper title content does not contain disease terms
        \textbf{Examples:}
        ├── "A Robust Example of Collider Bias in a Genetic Association Study"
        ├── "Genetic variants linked to education predict longevity"
        ├── "BGData - A Suite of R Packages for Genomic Analysis"
        └── "Efficient haplotype matching between a query and a panel"
\end{Verbatim}
~~~




### 3.6 Papers Without Abstract Sources (n=201)


Source data quality issue. These papers lack abstract content in paper.json due to:




<table>
  <thead>
    <tr>
      <th><strong>Category</strong></th>
      <th><strong>Possible Examples</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Letter-to-editor format</td>
      <td>Short correspondence without abstract section</td>
    </tr>
    <tr>
      <td>Repository cover pages</td>
      <td>Figshare/PMC deposit pages, not actual papers</td>
    </tr>
    <tr>
      <td>GROBID extraction failure</td>
      <td>Abstract present in PDF but not detected</td>
    </tr>
    <tr>
      <td>Preprint formats</td>
      <td>Non-standard layouts not parsed correctly</td>
    </tr>
  </tbody>
</table>



---


## 4. Critical Reflection


### 4.1 What Was Fixed (Prior to This Audit)



<table>
  <thead>
    <tr>
      <th><strong>Issue</strong></th>
      <th><strong>Solution</strong></th>
      <th><strong>Status</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Multi-tag filtering dropped title lines</td>
      <td>Implemented <code>match_mode: canonical</code> priority selection</td>
      <td>✓ Verified</td>
    </tr>
    <tr>
      <td>Witness models not dispatching</td>
      <td>Fixed YAML indentation in <code>resources.yaml</code></td>
      <td>✓ Verified</td>
    </tr>
    <tr>
      <td>Missing block-based abstract extraction</td>
      <td>Added <code>abstract_blocks</code> zone</td>
      <td>✓ Verified</td>
    </tr>
    <tr>
      <td>Ambiguous acronym normalization</td>
      <td>Added <code>corroborate</code> policy for short spans</td>
      <td>Configured</td>
    </tr>
  </tbody>
</table>



### 4.2 Canonical Tag Priority (Multi-Tag Resolution)




~~~{=html}
<pre class="notion-ascii-diagram"><code><strong>When a line has multiple tags (e.g., [title, section_header]):</strong>

<strong>Priority Order:</strong>
   1. title           ◄── Wins if present
   2. abstract
   3. table_caption
   4. figure_caption
   5. caption
   6. section_header
   7. list_item (if not also body)
   8. body
   9. reference_section
  10. reference
  11. citation
  12. unknown

<strong>Result:</strong> Line with [title, section_header] → canonical = &quot;title&quot;
        Filter tags_include: [title] → MATCH (not excluded)
</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
\textbf{When a line has multiple tags (e.g., [title, section_header]):}

\textbf{Priority Order:}
   1. title           ◄── Wins if present
   2. abstract
   3. table_caption
   4. figure_caption
   5. caption
   6. section_header
   7. list_item (if not also body)
   8. body
   9. reference_section
  10. reference
  11. citation
  12. unknown

\textbf{Result:} Line with [title, section_header] → canonical = "title"
        Filter tags_include: [title] → MATCH (not excluded)

\end{Verbatim}
~~~




### 4.3 What This Audit Confirms

1. **The NER pipeline is functioning correctly.** All configured zones extract content, all models dispatch and return results.
2. **The "78 missing papers" are not extraction failures.** They are:
    - 7 upstream data quality failures (broken paper.json)
    - 71 papers about non-disease topics (methods, software, population genetics)
3. **The 201 papers without abstract sources are a source data limitation.** The NER pipeline cannot extract from content that does not exist in the input paper.json.

### 4.4 Distinction: Pipeline Bug vs. Source Data Gap




~~~{=html}
<pre class="notion-ascii-diagram"><code>┌────────────────────────────────────────┬─────────────────────────────────────────┐
│   <strong>  SOURCE DATA GAP (not a bug)        │       PIPELINE BUG (needs fix)          │</strong>
├────────────────────────────────────────┼─────────────────────────────────────────┤
│ • paper.json has no abstract           │ • Abstract exists but                   │
│ • GROBID/OCR failed upstream           │   filter incorrectly drops              │
│ • Document format lacks abstract       │ • Model fails to process                │
│ • content_links.abstract.block_ids=[]  │ • Results not written                   │
├────────────────────────────────────────┼─────────────────────────────────────────┤
│ <strong>RESOLUTION:</strong> Fix PDF conversion         │ <strong>RESOLUTION:</strong> Fix NER pipeline            │
│             pipeline (G7/G9 stages)    │             logic/config                │
└────────────────────────────────────────┴─────────────────────────────────────────┘</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
┌────────────────────────────────────────┬─────────────────────────────────────────┐
│   \textbf{  SOURCE DATA GAP (not a bug)        │       PIPELINE BUG (needs fix)          │}
├────────────────────────────────────────┼─────────────────────────────────────────┤
│ • paper.json has no abstract           │ • Abstract exists but                   │
│ • GROBID/OCR failed upstream           │   filter incorrectly drops              │
│ • Document format lacks abstract       │ • Model fails to process                │
│ • content_links.abstract.block_ids=[]  │ • Results not written                   │
├────────────────────────────────────────┼─────────────────────────────────────────┤
│ \textbf{RESOLUTION:} Fix PDF conversion         │ \textbf{RESOLUTION:} Fix NER pipeline            │
│             pipeline (G7/G9 stages)    │             logic/config                │
└────────────────────────────────────────┴─────────────────────────────────────────┘
\end{Verbatim}
~~~








---


## 5. Next Steps


### 5.1 Validation Queries Post-Import




~~~{=html}
<pre class="notion-ascii-diagram"><code>SQL

<strong>-- Verify zone coverage
</strong>SELECT zone_name, COUNT(*) as units, COUNT(DISTINCT doc_id) as docs
FROM extraction_units
GROUP BY zone_name ORDER BY units DESC;

<strong>-- Verify witness flags populated
</strong>SELECT
    SUM(witness_bern2::int) as bern2,
    SUM(witness_gliner::int) as gliner,
    SUM(witness_pubmedbert::int) as pubmedbert
FROM disease_mentions;

<strong>-- Check source_type distribution
</strong>SELECT source_type, COUNT(*) FROM disease_mentions
GROUP BY source_type ORDER BY COUNT(*) DESC;</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
SQL

\textbf{-- Verify zone coverage
}SELECT zone_name, COUNT(*) as units, COUNT(DISTINCT doc_id) as docs
FROM extraction_units
GROUP BY zone_name ORDER BY units DESC;

\textbf{-- Verify witness flags populated
}SELECT
    SUM(witness_bern2::int) as bern2,
    SUM(witness_gliner::int) as gliner,
    SUM(witness_pubmedbert::int) as pubmedbert
FROM disease_mentions;

\textbf{-- Check source_type distribution
}SELECT source_type, COUNT(*) FROM disease_mentions
GROUP BY source_type ORDER BY COUNT(*) DESC;
\end{Verbatim}
~~~








### 5.2 Future Upstream Fixes Required



<table>
  <thead>
    <tr>
      <th><strong>Issue</strong></th>
      <th><strong>Affected Papers</strong></th>
      <th><strong>Fix Location</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Broken <code>reading_order.page_orders</code></td>
      <td>7</td>
      <td>PDF conversion pipeline (G2_04) MinerU</td>
    </tr>
    <tr>
      <td>Missing abstract detection</td>
      <td>201</td>
      <td>GROBID alignment (G4_02) or tag fusion (G7_00)</td>
    </tr>
  </tbody>
</table>



### 5.3 Long-Term Recommendations

1. **Abstract detection audit**: Run targeted audit on the 201 papers with missing abstracts to determine if abstract content is visually present in PDFs but not extracted.
2. **Reading order validation**: Add upstream validation in PDF conversion to flag papers where `reading_order.page_orders` has empty pages before export.
3. **Non-disease paper classification**: Consider adding a document-level classifier to identify methodology/software papers that would not be expected to contain disease mentions.













Scoring became a problem:







~~~{=html}
<pre class="notion-ascii-diagram"><code> <strong>zone_weights:</strong>
   title: 10.0  ◄── Too Low
   abstract: 5.0
   section_header: 3.0
   body: 1.0</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
 \textbf{zone_weights:}
   title: 10.0  ◄── Too Low
   abstract: 5.0
   section_header: 3.0
   body: 1.0
\end{Verbatim}
~~~



