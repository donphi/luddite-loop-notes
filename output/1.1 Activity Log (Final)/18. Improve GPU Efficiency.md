# Improve GPU Efficiency


## Content


## 1. Objective and Scope


The document processing pipeline converts academic PDFs into structured, machine-readable data through a sequence of CPU and GPU stages. Initial observation revealed that PDFs were processing strictly sequentially, each document waited for the previous to complete before entering the pipeline. This created significant GPU idle time, as expensive inference stages (OCR, layout detection, witness extraction) sat dormant between documents.



The objective was to redesign the pipeline's dependency graph to maximise GPU utilisation by allowing multiple documents to occupy different pipeline stages concurrently, and by identifying stages that could begin earlier than the naive sequential order would suggest.







Pipeline 1: 



G0–G10 (37 stages)







GPU-bound dispatch stages: 


- `G1_00` (PP-OCRv5)
- `G2_00` (Surya OCR)
- `G3_00` (Marker)
- `G3_01` (Docling)
- `G3_02` (PaddlePaddle),
- `G5_00` (TATR)
- `G6_00` (PP-OCRv5, PP-Structurev3)
- `G6_01` (LayoutLMv3).





---


## 2. Methods and Processing


### 2.1 Dependency Analysis


The pipeline was modelled as a directed acyclic graph (DAG) where each stage declares its upstream dependencies. The Prefect orchestration framework enforces these dependencies via wait_for parameters, but crucially allows independent branches to execute in parallel.







### 2.2 Pipeline Structure


The pipeline divides into five parallel branches after the preflight stages (G1), with a convergence point at fusion (G7).







Section A: Preflight (G1) — Sequential (Straight Line)





~~~{=html}
<pre class="notion-ascii-diagram"><code>┌─────────┐
│  G0_00  │  Orchestrator
│  Orch   │
└────┬────┘
     │
┌────▼────┐
│  G1_00  │  PDF → PNG (CPU Heavy)
│PDF→PNG  │
└────┬────┘
     │
┌────▼────┐
│  G1_01  │  Orientation Detection (CPU)
│ Orient  │
└────┬────┘
     │
┌────▼────┐
│  G1_02  │  Apply Rotation (CPU)
│Rotation │
└────┬────┘
     │
┌────▼────┐
│  G1_03  │  Probe &amp; Route (CPU)
│ Route   │
└─────────┘
</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
┌─────────┐
│  G0_00  │  Orchestrator
│  Orch   │
└────┬────┘
     │
┌────▼────┐
│  G1_00  │  PDF → PNG (CPU Heavy)
│PDF→PNG  │
└────┬────┘
     │
┌────▼────┐
│  G1_01  │  Orientation Detection (CPU)
│ Orient  │
└────┬────┘
     │
┌────▼────┐
│  G1_02  │  Apply Rotation (CPU)
│Rotation │
└────┬────┘
     │
┌────▼────┐
│  G1_03  │  Probe & Route (CPU)
│ Route   │
└─────────┘

\end{Verbatim}
~~~








Section B: Parallel Branches (G2–G6)



After G1_03 completes, five branches execute concurrently:





~~~{=html}
<pre class="notion-ascii-diagram"><code>                              G1_03 (Route)
                                   │
       ┌───────────┬───────────┬───┴───────┬───────────┬───────────┐
       │           │           │           │           │           │
       ▼           ▼           ▼           ▼           ▼           ▼
  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐
  │  G2_00  │ │  G3_00  │ │  G3_01  │ │  G3_02  │ │  G5_00  │ │  G6_00  │
  │  Surya  │ │ Marker  │ │ Docling │ │ Paddle  │ │  TATR   │ │PPStruct │
  │  (GPU)  │ │  (GPU)  │ │  (GPU)  │ │  (GPU)  │ │  (GPU)  │ │  (GPU)  │
  └────┬────┘ └────┬────┘ └────┬────┘ └────┬────┘ └────┬────┘ └────┬────┘
       │           │           │           │           │           │
     SPINE     ────┴──────────┬┴───────────┴───      TUBULAR    LAYOUT
     BRANCH                   │                      BRANCH     BRANCH
                            WITNESS
                            BRANCH
</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
                              G1_03 (Route)
                                   │
       ┌───────────┬───────────┬───┴───────┬───────────┬───────────┐
       │           │           │           │           │           │
       ▼           ▼           ▼           ▼           ▼           ▼
  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐
  │  G2_00  │ │  G3_00  │ │  G3_01  │ │  G3_02  │ │  G5_00  │ │  G6_00  │
  │  Surya  │ │ Marker  │ │ Docling │ │ Paddle  │ │  TATR   │ │PPStruct │
  │  (GPU)  │ │  (GPU)  │ │  (GPU)  │ │  (GPU)  │ │  (GPU)  │ │  (GPU)  │
  └────┬────┘ └────┬────┘ └────┬────┘ └────┬────┘ └────┬────┘ └────┬────┘
       │           │           │           │           │           │
     SPINE     ────┴──────────┬┴───────────┴───      TUBULAR    LAYOUT
     BRANCH                   │                      BRANCH     BRANCH
                            WITNESS
                            BRANCH

\end{Verbatim}
~~~




Section C: Branch Details





~~~{=html}
<pre class="notion-ascii-diagram"><code>SPINE (G2)                       WITNESS (G3)              HEADER (G4)
──────────                       ────────────              ───────────
G2_00 Surya Extract              G3_00 Marker    ┐        G4_00 GROBID
   │                             G3_01 Docling   ├─►      G4_01 MetaNorm
   ├──► G2_01 Line Build         G3_02 Paddle    ┘        G4_02 HeaderQC
   │       │                          │
   │       └──► G2_03 LineQC          ▼                * Starts from G1_02
   │                             G3_03 WitnessQC          (before Route)
   └──► G2_02 Word Build
           │
           └──► G2_04 WordQC


TABULAR (G5)               LAYOUT (G6)
────────────               ───────────
G5_00 TATR Detect          G6_00 PP-Structure
   │                          │
   └──► G5_01 Structure       ├──► G6_01 LayoutLM ◄── G2_02
           │                  │         │
           └──► G5_02 Cell    │         └──► G6_02 LayoutQC
                   │          │
                   ├──► G5_03 TabularQC
                   │
                   └──► G5_04 TabularMD
</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
SPINE (G2)                       WITNESS (G3)              HEADER (G4)
──────────                       ────────────              ───────────
G2_00 Surya Extract              G3_00 Marker    ┐        G4_00 GROBID
   │                             G3_01 Docling   ├─►      G4_01 MetaNorm
   ├──► G2_01 Line Build         G3_02 Paddle    ┘        G4_02 HeaderQC
   │       │                          │
   │       └──► G2_03 LineQC          ▼                * Starts from G1_02
   │                             G3_03 WitnessQC          (before Route)
   └──► G2_02 Word Build
           │
           └──► G2_04 WordQC


TABULAR (G5)               LAYOUT (G6)
────────────               ───────────
G5_00 TATR Detect          G6_00 PP-Structure
   │                          │
   └──► G5_01 Structure       ├──► G6_01 LayoutLM ◄── G2_02
           │                  │         │
           └──► G5_02 Cell    │         └──► G6_02 LayoutQC
                   │          │
                   ├──► G5_03 TabularQC
                   │
                   └──► G5_04 TabularMD

\end{Verbatim}
~~~




Section D: Convergence (G7–G10)





~~~{=html}
<pre class="notion-ascii-diagram"><code>         G2_01 ──┐
         G4_01 ──┼──► G7_00 Fusion ──► G7_01 FusionQC
         G5_02 ──┤         │
         G6_00 ──┤         │
         G6_01 ──┘         │
                           │
              ┌────────────┴────────────┐
              │                         │
              ▼                         ▼
    ┌───────────────────┐     ┌───────────────────┐
    │ G8_00 Text Audit  │     │ G8_01 Table Audit │
    │ (G7_00, G3_00,    │     │ (G5_02)           │
    │  G3_01)           │     │                   │
    └─────────┬─────────┘     └─────────┬─────────┘
              │                         │
              └────────────┬────────────┘
                           │
                           ▼
                    G8_02 Audit Report
                           │
                           ▼
                    G9_00 Export JSON
                           │
                           ▼
                    G9_01 Provenance
                           │
                           ▼
                    G10_00 Metrics ◄── (all QC stages)
                           │
                           ▼
                    G10_01 Scorecard
</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
         G2_01 ──┐
         G4_01 ──┼──► G7_00 Fusion ──► G7_01 FusionQC
         G5_02 ──┤         │
         G6_00 ──┤         │
         G6_01 ──┘         │
                           │
              ┌────────────┴────────────┐
              │                         │
              ▼                         ▼
    ┌───────────────────┐     ┌───────────────────┐
    │ G8_00 Text Audit  │     │ G8_01 Table Audit │
    │ (G7_00, G3_00,    │     │ (G5_02)           │
    │  G3_01)           │     │                   │
    └─────────┬─────────┘     └─────────┬─────────┘
              │                         │
              └────────────┬────────────┘
                           │
                           ▼
                    G8_02 Audit Report
                           │
                           ▼
                    G9_00 Export JSON
                           │
                           ▼
                    G9_01 Provenance
                           │
                           ▼
                    G10_00 Metrics ◄── (all QC stages)
                           │
                           ▼
                    G10_01 Scorecard

\end{Verbatim}
~~~




### 2.3 Early-Start Optimisation


A critical observation: GROBID (G4_00) requires only the rotated PNGs, not the routing decision. By declaring G4_00's dependency as G1_02 rather than G1_03, the header extraction branch begins one stage earlier, reducing overall latency.





~~~{=html}
<pre class="notion-ascii-diagram"><code>**OLD**
**Standard (Naive):**     G1_00 → G1_01 → G1_02 → G1_03 → G4_00

**NEW**
**Optimised:**            G1_00 → G1_01 → G1_02 ──────────► G4_00
                                         └──► G1_03 → (other branches)
</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
**OLD**
**Standard (Naive):**     G1_00 → G1_01 → G1_02 → G1_03 → G4_00

**NEW**
**Optimised:**            G1_00 → G1_01 → G1_02 ──────────► G4_00
                                         └──► G1_03 → (other branches)

\end{Verbatim}
~~~




---


## 3. Key Findings and Technical Outcomes


### 3.1 GPU Stage Distribution



<table>
  <thead>
    <tr>
      <th>Group</th>
      <th>Stage</th>
      <th>Model</th>
      <th>Queue Name</th>
      <th>Typical Duration</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>G2</td>
      <td>G2_00</td>
      <td>Surya OCR</td>
      <td>spine_jobs</td>
      <td>15–45s</td>
    </tr>
    <tr>
      <td>G3</td>
      <td>G3_00</td>
      <td>Marker</td>
      <td>marker_jobs</td>
      <td>30–90s</td>
    </tr>
    <tr>
      <td>G3</td>
      <td>G3_01</td>
      <td>Docling</td>
      <td>docling_jobs</td>
      <td>20–60s</td>
    </tr>
    <tr>
      <td>G3</td>
      <td>G3_02</td>
      <td>PaddleOCR</td>
      <td>paddle_jobs</td>
      <td>15–40s</td>
    </tr>
    <tr>
      <td>G5</td>
      <td>G5_00</td>
      <td>TATR Detection</td>
      <td>tatr_detect_jobs</td>
      <td>10–30s</td>
    </tr>
    <tr>
      <td>G6</td>
      <td>G6_00</td>
      <td>PP-Structure</td>
      <td>ppstructure_jobs</td>
      <td>8–25s</td>
    </tr>
    <tr>
      <td>G6</td>
      <td>G6_01</td>
      <td>LayoutLMv3</td>
      <td>layoutlm_jobs</td>
      <td>12–35s</td>
    </tr>
  </tbody>
</table>



### 3.2 Parallelism Characteristics


With max_parallel_documents: X on the RTX 6000 profile, the pipeline can maintain X documents in-flight simultaneously. We still need to test the maximum effiency value for PDF’s per Orchestration Docker Container However, the staggered benefits are:


- Document A occupies G2_00 (Surya) while Document B completes G1_03
- Document A moves to G3_00–G3_02 while Document B enters G2_00
- GPU workers remain occupied across the full processing window





### 3.3 Dependency Graph Metrics

- **Total stages:** 37 (G0_00 through G10_01)
- **GPU dispatch stages:** 7
- **Maximum parallel branches:** 6 (after G1_03)
- **Critical path length:** 15 stages (G0→G1→G2→G7→G8→G9→G10)
- **Early-start candidates identified:** 1 (G4 branch)





---


## 4. Critical Reflection


The initial pipeline implementation processed documents in strict linear sequence, a design inherited from single-document debugging workflows. While functionally correct, this approach created a characteristic sawtooth pattern in GPU utilisation: brief spikes during inference stages followed by extended idle periods as CPU-bound stages executed. For a corpus of several thousand PDFs, this inefficiency compounds into days of unnecessary processing time.



The parallelisation strategy addresses this through two mechanisms. First, allowing multiple documents to occupy the pipeline simultaneously ensures that while one document undergoes CPU-intensive token building, another can utilise the GPU for OCR,  layout detection and Tabular detection all at once. Second, the early-start optimisation for the header extraction branch demonstrates that careful dependency analysis can reveal latency reductions invisible to naive sequential thinking.



However, several limitations warrant acknowledgement. The current implementation assumes homogeneous document complexity; in practice, a 200-page PDF in the G3_00 Marker stage will block that worker far longer than a 10-page document, potentially creating downstream starvation. The RabbitMQ queue architecture provides natural load balancing, but does not prioritise shorter jobs. 



The dispatch and worker pattern for GPU stages, where persistent docker container workers consume jobs from queues rather than spawning per-document, proved essential. Model loading times for Surya, Marker, and the transformer-based layout models range from 30 - 60 seconds; amortising this cost across hundreds of documents transforms what would be a dominant overhead into a negligible one-time startup expense.







---


## 5. Next Steps


Immediate priorities:


1. **Benchmark parallel throughput:** Measure end-to-end processing time with 1, 2, and 4 concurrent documents to quantify the parallelisation benefit and identify the optimal concurrency level for the available hardware.
2. **Implement job prioritisation:** Extend the RabbitMQ dispatch layer to estimate document complexity (page count, image density) and schedule shorter jobs preferentially to reduce head-of-line blocking. `TO BE DONE LATER`
3. **GPU memory monitoring:** Add runtime VRAM tracking to detect memory pressure during concurrent GPU stage execution and dynamically throttle batch sizes.

Longer-term considerations:


1. **Profile-specific concurrency tuning:** The DGX B200 profile with 192GB VRAM per GPU could support higher parallelism; the configuration system should expose `max_parallel_documents` as a hardware-dependent parameter.
2. **Stage-level checkpointing:** For documents that fail mid-pipeline, implement granular restart from the last successful stage rather than full reprocessing.
3. **Cross-document batching:** Investigate whether GPU stages could batch pages from multiple documents into single inference calls, further improving throughput for small documents.








