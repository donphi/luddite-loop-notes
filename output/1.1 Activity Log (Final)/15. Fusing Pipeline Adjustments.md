# Fusing Pipeline Adjustments


## Content






## 1. Objective and scope


The objective is to lock a deterministic, scalable fusion strategy (G7) that can operate across 10,000–100,000 PDFs without fuzzy logic and without introducing a second coordinate system.







Scope:


- Inputs: canonical geometry and tokens from G2, hierarchy from G6, tables from G5, identity/header from G4, and downstream audit hooks (G3/G8).
- Output: a **single canonical JSON** (`/fusion/{doc_id}/candidate.json`) that supports:
    - ElasticSearch, Name Entity Recognition Models & Embedding Models
    - **round-trip traceability**: `ES/NER hit → token span → bbox/polygon → page image` for human-in-the-loop visual review.
- Constraint: <u>**absolute keys only**</u>. No fuzzy matching in fusion. Any cross-source alignment must be performed via explicit token IDs or explicit indices.





---


## 2. Methods and process


### 2.1 Key/foreign-key analysis (HARD JOINS)


The fusion design is validated by enumerating each upstream output file and confirming:


- Primary key(s) exist,
- Foreign keys exist and are join-compatible,
- Join is deterministic (exact match only),
- Missing join edges are noted

### Summary: current state of keys



<table>
  <thead>
    <tr>
      <th>Group</th>
      <th>Output</th>
      <th>Primary Key</th>
      <th>Foreign Keys</th>
      <th>Hard Join Status</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>G2</td>
      <td><code>line_tokens.jsonl</code></td>
      <td><code>token_id</code></td>
      <td><code>doc_id, page_num, page_id, region_id</code></td>
      <td>✅ SOLID</td>
    </tr>
    <tr>
      <td>G2</td>
      <td><code>word_tokens.jsonl</code></td>
      <td><code>token_id</code></td>
      <td><code>doc_id, page_num, page_id, line_index, line_bbox</code></td>
      <td>✅ SOLID</td>
    </tr>
    <tr>
      <td>G2</td>
      <td><code>reading_order_voted.json</code></td>
      <td><code>(doc_id, page_num)</code></td>
      <td><code>order[] → line_index</code></td>
      <td>✅ SOLID</td>
    </tr>
    <tr>
      <td>G4</td>
      <td><code>alignment.json / metadata.json</code></td>
      <td><code>doc_id</code></td>
      <td><code>title_coords[], abstract_coords[]</code></td>
      <td>⚠️ Missing deterministic token anchors</td>
    </tr>
    <tr>
      <td>G5</td>
      <td><code>tables.jsonl</code></td>
      <td><code>table_id</code></td>
      <td><code>page_num, cell_id, token_ids[]</code></td>
      <td>✅ SOLID</td>
    </tr>
    <tr>
      <td>G5</td>
      <td><code>tatr_detections.json</code></td>
      <td><code>table_id</code></td>
      <td><code>page_num, table_bbox</code></td>
      <td>✅ SOLID</td>
    </tr>
    <tr>
      <td>G5</td>
      <td><code>tatr_structures.json</code></td>
      <td><code>table_id</code></td>
      <td><code>row_idx, col_idx, cell_bbox</code></td>
      <td>✅ SOLID</td>
    </tr>
    <tr>
      <td>G5</td>
      <td><code>cells.json</code></td>
      <td>- (summary)</td>
      <td>references <code>table_id</code></td>
      <td>✅ Summary only</td>
    </tr>
    <tr>
      <td>G6</td>
      <td><code>regions.jsonl</code></td>
      <td><code>region_id</code> (<code>p1_r0</code>)</td>
      <td><code>page, page_file, bbox, type</code></td>
      <td>⚠️ Lacks explicit token linkage</td>
    </tr>
    <tr>
      <td>G6</td>
      <td><code>semantic_labels.jsonl</code></td>
      <td><code>token_id</code></td>
      <td><code>matched_region_type, semantic_label</code></td>
      <td>✅ SOLID</td>
    </tr>
    <tr>
      <td>G3</td>
      <td><code>docling_audit.jsonl</code></td>
      <td><code>(page, line_id)</code></td>
      <td>-</td>
      <td>⚠️ Needs token mapping</td>
    </tr>
  </tbody>
</table>



### 2.2 Join diagram


# Schema Diagram




~~~{=html}
<pre class="notion-ascii-diagram"><code>                ┌─────────────────┐
                │    <strong> DOC_ID  </strong>    │
                │    {doc_id}     │
                └────────┬────────┘
                         │
       ┌─────────────────┼─────────────────┐
       │                 │                 │
       ▼                 ▼                 ▼
┌─────────────┐  ┌─────────────┐  ┌─────────────┐
│  <strong>G2 SPINE</strong>   │  │  <strong>G4 HEADER</strong>  │  │ <strong>G5 TABULAR</strong>  │
│ line_tokens │  │  alignment  │  │ tables.jsonl│
├─────────────┤  ├─────────────┤  ├─────────────┤
│<strong>PK:</strong> token_id │◄─┤⚠️ MISSING   │  │<strong>PK:</strong> table_id │
│<strong>FK:</strong> doc_id   │  │title_token_ │  │<strong>FK:</strong> page_num │
│<strong>FK:</strong> page_num │  │ids          │  │             │
│<strong>FK:</strong> region_id│  │abstract_    │  │<strong>cells[]:</strong>     │
│             │  │token_ids    │  │ <strong>PK:</strong> cell_id │
│line_index   │  └─────────────┘  │ <strong>FK:</strong> token_  │
└──────┬──────┘                   │     ids[]   │──┐
       │                          └─────────────┘  │
       │ (page_num, line_index)                    │
       ▼                                           │
┌─────────────┐  ┌─────────────┐                   │
│  <strong>G2 SPINE </strong>  │  │ <strong>G6 HIERARCHY</strong>│                   │
│ word_tokens │  │regions.jsonl│                   │
├─────────────┤  ├─────────────┤                   │
│<strong>PK:</strong> token_id │◄─┤⚠️ MISSING FK│                   │
│<strong>FK:</strong> line_idx │  │token_ids[]  │                   │
│<strong>FK:</strong> page_num │  │             │                   │
│word_index   │  │<strong>PK:</strong> region_id│                   │
└──────┬──────┘  │<strong>FK:</strong> page     │                   │
       │         └─────────────┘                   │
       │                                           │
       │◄──────────────────────────────────────────┘
       │         ┌─────────────┐
       │         │ <strong>G6 HIERARCHY</strong>│
       └────────►│semantic_    │
        <strong>FK:</strong>      │labels       │
        token_id ├─────────────┤
                 │<strong>PK:</strong> token_id │ ✅ GOOD
                 │semantic_lbl │
                 └─────────────┘

┌─────────────┐
│  <strong>G2 SPINE</strong>   │
│reading_order│
│_voted.json  │
├─────────────┤
│<strong>FK:</strong> doc_id   │
│<strong>FK:</strong> page_num │
│order[] →    │──► line_index
│ line_index  │
└─────────────┘</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
                ┌─────────────────┐
                │    \textbf{ DOC_ID  }    │
                │    \textbraceleft{\textbraceright{}doc_id\textbraceright{}     │
                └────────┬────────┘
                         │
       ┌─────────────────┼─────────────────┐
       │                 │                 │
       ▼                 ▼                 ▼
┌─────────────┐  ┌─────────────┐  ┌─────────────┐
│  \textbf{G2 SPINE}   │  │  \textbf{G4 HEADER}  │  │ \textbf{G5 TABULAR}  │
│ line_tokens │  │  alignment  │  │ tables.jsonl│
├─────────────┤  ├─────────────┤  ├─────────────┤
│\textbf{PK:} token_id │◄─┤⚠️ MISSING   │  │\textbf{PK:} table_id │
│\textbf{FK:} doc_id   │  │title_token_ │  │\textbf{FK:} page_num │
│\textbf{FK:} page_num │  │ids          │  │             │
│\textbf{FK:} region_id│  │abstract_    │  │\textbf{cells[]:}     │
│             │  │token_ids    │  │ \textbf{PK:} cell_id │
│line_index   │  └─────────────┘  │ \textbf{FK:} token_  │
└──────┬──────┘                   │     ids[]   │──┐
       │                          └─────────────┘  │
       │ (page_num, line_index)                    │
       ▼                                           │
┌─────────────┐  ┌─────────────┐                   │
│  \textbf{G2 SPINE }  │  │ \textbf{G6 HIERARCHY}│                   │
│ word_tokens │  │regions.jsonl│                   │
├─────────────┤  ├─────────────┤                   │
│\textbf{PK:} token_id │◄─┤⚠️ MISSING FK│                   │
│\textbf{FK:} line_idx │  │token_ids[]  │                   │
│\textbf{FK:} page_num │  │             │                   │
│word_index   │  │\textbf{PK:} region_id│                   │
└──────┬──────┘  │\textbf{FK:} page     │                   │
       │         └─────────────┘                   │
       │                                           │
       │◄──────────────────────────────────────────┘
       │         ┌─────────────┐
       │         │ \textbf{G6 HIERARCHY}│
       └────────►│semantic_    │
        \textbf{FK:}      │labels       │
        token_id ├─────────────┤
                 │\textbf{PK:} token_id │ ✅ GOOD
                 │semantic_lbl │
                 └─────────────┘

┌─────────────┐
│  \textbf{G2 SPINE}   │
│reading_order│
│_voted.json  │
├─────────────┤
│\textbf{FK:} doc_id   │
│\textbf{FK:} page_num │
│order[] →    │──► line_index
│ line_index  │
└─────────────┘
\end{Verbatim}
~~~




### 2.3 Fusion assembly model (proposed representation)


The fusion output is treated as a page-scoped block graph with token-level provenance:





~~~json
{
  "doc_id": "101002alz13610_...",
  "doi": "10.1002/alz.13610",
  "title": "Genetic risk score...",
  "pages": [
    {
      "page_num": 1,
      "blocks": [
        {
          "block_id": "p1_block_001",
          "block_type": "title",
          "reading_order": 0,
          "tokens": [
            {
              "token_id": "..._0000001",
              "text": "Genetic",
              "bbox": [...],
              "semantic_label": "doc_title",
              "in_table": null,
              "grobid_field": "title"
            }
          ]
        },
        {
          "block_id": "p1_block_002",
          "block_type": "table",
          "table_id": "..._table_0001",
          "cells": [...]
        }
      ]
    }
  ]
}

~~~








---


## 3. Key Technical Outcomes


### 3.1 G2: Hard join Anchor (Surya) ✅

- `line_tokens.jsonl` is the **document backbone** for reading order and line-level text.
- `word_tokens.jsonl` (built from `char-tokens`) is the **atomic join substrate** enabling:
    - table cell projection (`token_ids[]`),
    - semantic labels,
    - ES & NER entity bounding boxes via token spans.

Outcome: G7 must treat G2 tokens as the only geometric co-ordinates.







### 3.2 G2: Reading Order Source (MinerU) ✅

- Fusion should consume `reading_order_voted.json` (not `reading_order.json`) to ensure:
    - deterministic order per page,
    - consistent downstream chunking and indexing.

Outcome: block ordering should reference voted reading order.







### 3.3 G5: Table Token-Anchored (TATR) ✅

- `tables.jsonl` already carries `cells[].token_ids[]` and can therefore attach tables into the fused graph deterministically.
- `cells.json` is a summary/index and should not be used as the source of cell text.

Outcome: Fusion consumes tables.jsonl as the table truth.







### 3.4 G6: Layout Structure (PP & LayoutLMv3) ⚠️

- `regions.jsonl` defines region geometry and types, but lacks explicit `token_ids[]` or `line_indices[]`.
- `semantic_labels.jsonl` is join-ready on `token_id` and can annotate tokens, but does not by itself provide a region membership edge unless stored.

Outcome: to enable deterministic “block formation” and clean border junk removal, regions must expose explicit membership, either:


- `regions[].token_ids[]` (word-level), or
- `regions[].line_indices[]` (line-level).





### 3.5 G4: Metadata (GROBID) ❌

- `metadata.json` has `title_coords[]` and `abstract_coords[]` empty.
- Without `title_token_ids[]` / `abstract_token_ids[]`, G4 cannot be fused into the token graph deterministically.

Outcome: G4 must emit token anchors (not only coords) for any field you want to highlight or trace back to geometry.







### 3.6 G3: Witnesses (Marker & Docling) ❌

- G3 audit outputs are not currently token-resolvable.
- To make audits deterministic and comparable, the witness layer must be able to map its extracted text to spine `token_id` spans.

Outcome: add token mapping only in audit (G8) unless you explicitly want G3 to become token-aware.







---


## 4. Critical reflection

1. **The fusion join is the highest-stakes part of the entire pipeline.**

    If the join is non-deterministic, every downstream “scientific” output (ES features, NER tags, RAG chunks, DuckDB stats) becomes non-reproducible because entities cannot be re-projected onto the page reliably.
    

2. **Token IDs must remain the only backbone for traceability.**

    Any system that tries to align on raw text strings or fuzzy similarity will drift at 10 - 100k scale due to OCR variance, hyphenation, ligatures, and layout artifacts. This is unacceptable for human verification and statistical defensibility.
    

3. **Region membership is not optional.**

    Without a deterministic edge token_id → region_id (or region→token list), you cannot:
    

    - remove headers/footers consistently,
    - filter references reliably,
    - form stable “blocks” that survive across runs.
4. **GROBID geometry is not required for correctness, but token anchors are required for usability.**

    For fusion and downstream analysis, metadata can live as identity fields. However, if the UI requires “highlight title/abstract on the PDF image”, that must be done via token anchors, not via brittle DPI coordinate transforms.
    






---


## 5. Next steps


### 5.1 Enforce the “final verdict” actions (no extras)



<table>
  <thead>
    <tr>
      <th>Group</th>
      <th>File</th>
      <th>Hard Join Ready?</th>
      <th>Action Needed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>G2</td>
      <td><code>line_tokens.jsonl</code></td>
      <td>✅ YES</td>
      <td>None (anchor)</td>
    </tr>
    <tr>
      <td>G2</td>
      <td><code>word_tokens.jsonl</code></td>
      <td>✅ YES</td>
      <td>None</td>
    </tr>
    <tr>
      <td>G2</td>
      <td><code>reading_order_voted.json</code></td>
      <td>✅ YES</td>
      <td>Use this (not <code>reading_order.json</code>)</td>
    </tr>
    <tr>
      <td>G4</td>
      <td><code>alignment.json</code></td>
      <td>❌ NO</td>
      <td>Add <code>title_token_ids[]</code>, <code>abstract_token_ids[]</code></td>
    </tr>
    <tr>
      <td>G4</td>
      <td><code>metadata.json</code></td>
      <td>❌ NO</td>
      <td>Same as <code>alignment.json</code></td>
    </tr>
    <tr>
      <td>G5</td>
      <td><code>tables.jsonl</code></td>
      <td>✅ YES</td>
      <td>None (already token-anchored)</td>
    </tr>
    <tr>
      <td>G5</td>
      <td><code>tatr_detections.json</code></td>
      <td>✅ YES</td>
      <td>None</td>
    </tr>
    <tr>
      <td>G5</td>
      <td><code>tatr_structures.json</code></td>
      <td>✅ YES</td>
      <td>None</td>
    </tr>
    <tr>
      <td>G5</td>
      <td><code>cells.json</code></td>
      <td>✅ YES</td>
      <td>Treat as summary only; use <code>tables.jsonl</code></td>
    </tr>
    <tr>
      <td>G6</td>
      <td><code>regions.jsonl</code></td>
      <td>⚠️ PARTIAL</td>
      <td>Add <code>token_ids[]</code> or <code>line_indices[]</code></td>
    </tr>
    <tr>
      <td>G6</td>
      <td><code>semantic_labels.jsonl</code></td>
      <td>✅ YES</td>
      <td>None (already token-anchored)</td>
    </tr>
    <tr>
      <td>G3</td>
      <td><code>docling_audit.jsonl</code></td>
      <td>❌ NO</td>
      <td>Add token mapping (ideally in G8)</td>
    </tr>
    <tr>
      <td>G3</td>
      <td><code>marker_audit.jsonl</code></td>
      <td>❌ NO</td>
      <td>Add token mapping (ideally in G8)</td>
    </tr>
  </tbody>
</table>



### 5.2 Minimal script changes required to make the join complete


G4 (header alignment)


- Add:
    - `title_token_ids[]`
    - `abstract_token_ids[]`
- Source of truth for token IDs:
    - exact spans found in the G2 spine (word tokens), not fuzzy matching.

G6 (regions membership)


- Add one of:
    - `regions[].token_ids[]` (preferred if you want token-level blocks), or
    - `regions[].line_indices[]` (acceptable if block formation happens at line level)
- Ensure these memberships are computed deterministically from geometry overlap thresholds.

G7 (fusion builder)


- Build blocks using only:
    - `token_id` joins (for labels/tables/metadata anchors),
    - or `line_index` joins where explicitly defined (reading order).
- Do not introduce fuzzy matching for metadata, headings, or region assignment.





### 5.3 Lock the downstream contract for ES, NER, RAG


Add (as a later stage, not inside G2):


- an ES, NER prep view that writes:
    - canonical cleaned text,
    - mapping table:
        - `(doc_id, view_id, token_id, char_start_clean, char_end_clean)`
- store ES, NER hits as:
    - `(doc_id, view_id, char_start_clean, char_end_clean)` → mapped back to `token_id[]` → bbox.

This preserves:


- one geometric coordinate system (tokens),
- optional char offsets as an interoperability layer only.




