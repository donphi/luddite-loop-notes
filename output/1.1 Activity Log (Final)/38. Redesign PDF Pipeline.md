# Redesign PDF Pipeline


## Content


## 1. Objectives


Redesign the PDF → Clean JSON pipeline to address architectural and operational issues that emerged during iterative development. The initial 12-script pipeline grew organically without centralised control, creating maintenance overhead, debugging difficulty, and inefficient resource utilisation.







---


## 2. Methods and Processes


The pipeline was constructed incrementally using a numbered script convention (XX-name-action.py, and some examples include: 00-orchestrate_run.py, 01-preflight_convert_to_png.py, etc.) with separate scripts for each processing stage. Processing stages included PDF conversion, OCR, LayoutLM inference, TATR table detection, pixel-space reconciliation, and JSON normalisation.



Container architecture separated CPU and GPU workloads via Docker Compose, with dispatch scripts routing work to GPU workers. Hyperparameters were embedded within individual scripts. A partial centralisation existed via config/resources.yaml and four utility scripts in lib/, but this was incomplete.







---


### Technical Constraints Encountered


Hardware-Software Compatibility


- PaddleOCR requires CUDA 12.9 for Blackwell architecture (RTX 6000 Pro). Required Dockerfile modification to load nightly CUDA 12.9 builds.
- PP-Structure library dependency not initially included; required additional installation step within the Dockerfile.
- Marker exhibited limitations requiring Docling as supplementary witness.





Resource Allocation


- No per-container hardware specification. PDFs flowed Processing times varied significantly across GPU profiles but were not systematically recorded (note: benchmark time per Group per PDF average with RTX 6000 Pro for future reference).
- Linear execution model caused GPU idle time while waiting on sequential file processing.





Data Flow Issues


- Table bounding boxes required specific format for LayoutLMv3 input; mismatch caused downstream failures.
- Manifest integrity problems; contract between stages was implicit rather than enforced.
- Report files lacked consistent naming (`report.json` convention needed for collation).
- Besides GPU idle time with sequential linear pipeline, we need a way to efficiently increase the flow of PDFs. We need a way to run mulitple GPU containers at the same time and have the files flow asymetcially through the pipeline.





---


### Architectural Limitations Identified


Centralisation Failures


- Hyperparameters scattered across individual scripts. Changing GPU profile required editing every script, no single YAML source of truth. We were considering testing the pipeline on a DGX B200 with eight GPUs and for this we needed better pipeline flow.
- Logging implemented per-script with no unified aggregation. Failures occurred without clear indication of location.
- Verification/validation steps existed in some stages but not all, and were not centrally orchestrated.





Naming and Structure


- Numbered prefix convention (`00_`, `01_`, etc.) created cascade effect: inserting or reordering stages required renaming downstream scripts. ie `00_ - 01_ - … - 12_ … - 26_`
- Folder organisation did not reflect logical groupings (e.g., by processing phase or resource type).
- Variable naming inconsistent across scripts.

Code Drift


- No template structure for script types (CPU worker, GPU worker, GPU dispatch). Each script developed independently, leading to structural divergence.
- More shared methods could exist in `lib/` which can enforce consitant outputs. ie. Add independant central `lib/logging.py`, `lib/contract.py` and `lib/manifest.py` scripts the pipeline can pull from.
- Iterative development broke logic in earlier scripts; no regression mechanism.





Orchestration Gaps


- Orchestrator existed but did not fully control flow through `lib/*.py` and `config/`. Possible research dedicated orchestrator libraries in python.
- No `lib/compute.py` or equivalent for CPU parallelisation. CPU compute remains just as important as GPU.
- No aggregated pass/fail status per PDF across pipeline stages.





---


## 3. Critical Reflection


### 3.1 Architectural Foundations


The core problem was building forward without architectural scaffolding. The pipeline grew because each new requirement (orientation detection, table extraction, structure normalisation) was solved locally rather than designed into a coherent system. This is a normal part of exploratory development, but the transition point, where exploration should become engineering, was missed.







### 3.2 Centralisation and Configuration


The numbered naming convention felt like structure but actually created rigidity. It optimised for human readability of execution order at the cost of maintainability. A better approach groups by function (preprocessing, extraction, validation) with orchestration handling order.



The lack of centralised configuration was the most expensive mistake. Every parameter change required multi-file edits, increasing both effort and error probability. The lesson here is that configuration centralisation is not optional infrastructure, it is prerequisite infrastructure.







### 3.3 Structure and Observability


Logging and validation were treated as secondary concerns. In a multi-stage pipeline, these are primary concerns. Without unified logging, debugging becomes archaeology. Without validation contracts between stages, errors propagate silently. This includes maintaining a well organised manifest that can be scrutinised post-pipeline render.



The Docker Compose separation of CPU and GPU workers was a correct decision. The dispatch pattern worked. What was missing was the layer above: an orchestrator that understands the full Directed Acyclic Graph, (DAG), manages retries, and provides observability. This is what Prefect or a message queue like RabbitMQ would provide. I plan to reseach DAGs and their orchestrators more.



Underrated learning: naming conventions and structural consistency matter more as pipelines scale. At 12 scripts this was manageable. At 20+ scripts without templates and conventions, it becomes unmanageable. Script drift is real.







### 3.4 Scalability


Scalability and scoping for scaliblity was the real challenge and ensuring that the code and process was never brittle was the largest tasks. Usually managing a few 100 files for manipulation become a much easier code decisions than thousands. I kept wanting to use regex for very specific maniuplation but realised that this might only work on a few PDFs.



Scalability and scoping for scalability was the real challenge. Managing a few hundred files for manipulation leads to very different code decisions than managing thousands. At small scale, edge cases are rare enough to fix manually or ignore. At large scale, edge cases become a guaranteed percentage of every run.
A pattern that matches 95% of documents in a 100-file test set will fail on 400 documents when processing 8,000 papers. The failure rate stays constant; the absolute number of failures scales linearly. What looks like a working solution at small scale becomes a maintenance burden at production scale.



This exposed a deeper problem: I was optimising for the sample rather than the population. Real-world academic PDFs vary enormously, different publishers, different templates, single-column vs multi-column, tables as images vs tables as text. Character bounding boxes (char-boxes) and vertical large tables became a clear problem within the pipeline. Some born-digital PDFs store text as individual characters, each with its own bounding box, rather than grouping characters into words. Non-OCR extraction tools read this structure directly and inherit the fragmentation: each character returns as a separate entity with no word-level grouping. The word "biomarker" becomes nine separate tokens: “b”, “i”, “o”, “m”, “a”, “r”, “k”, and downstream processing expecting word-level input breaks entirely. Expecting a semantic model to make sense of indidividual characters is incredibly brittle. OCR would handle these PDFs correctly because it reconstructs words from the visual layer rather than the PDF structure, but running OCR on every born-digital PDF is computationally wasteful. Using OCR on every single journal would be ineffective and costly, and so a preflight audit needs to be considered before even starting the pipeline. The pipeline needed to either handle this variance or fail gracefully with clear reporting. Without per-document pass/fail tracking and report collation, I had no way to know the true failure rate or which failure modes were most common.
Relying on a single model or library for any extraction task also became a clear risk. A model reports confidence scores, but confidence is self-assessed, it does not guarantee correctness. A library may work well on the PDFs it was trained or tested on, but fail silently on edge cases outside that distribution. The solution is to use witnesses: multiple independent models or methods processing the same input, with results compared for agreement. Using an odd number of witnesses (three, for instance) allows majority voting without ties. Where all three agree, confidence is high. Where they disagree, the document is flagged for review or routed to a fallback process. This is more robust than hoping a single model performs as advertised, it provides coverage checking and a form of accuracy verification through consensus. The computational cost increases, but the reliability gain at scale justifies it.







### 3.5 Documentation


Documentation for each group of scripts is essential when the pipeline becomes too large. At 12 scripts, the logic can be held in memory. At 20+, it cannot. Without documentation, returning to the pipeline after even a few days means re-reading scripts to reconstruct what each stage does, what inputs it expects, and what outputs it produces. This is expensive time spent on orientation rather than development.
The mistake is treating documentation as a post-build task. By the time the pipeline is large enough to need documentation, the effort required to write it retrospectively is significant and the details have already started to fade. Documentation needs to be written as each group is built, when the logic is fresh and the design decisions are still clear. A brief structure.md allowing a general over view of the entire process while a sub_structure.md allows for more granular documenation which is specified per python file. These both woudl  capture the processing group (preprocessing, extraction, validation) that describes purpose, inputs, outputs, dependencies, and known limitations is sufficient. It does not need to be exhaustive; it needs to be navigable.
This also serves as a forcing function for clarity. If a script's purpose cannot be summarised in a few sentences, that is a signal the script may be doing too much or its role in the pipeline is not well-defined. Writing documentation surfaces these problems early.







---


## 4. Lessons Learned

1. Configuration must be centralised before the second script is written.
2. Every stage needs a validation contract: defined inputs, defined outputs, explicit pass/fail.
3. Templates for script types (CPU, GPU, dispatch, worker) prevent structural drift.
4. Logging must be unified from the start—retrofitting is painful.
5. Naming conventions should optimise for modification, not just initial readability.
6. Linear execution with GPU resources is wasteful; parallelisation and queuing are not optimisations, they are requirements.
7. The transition from exploration to engineering must be deliberate—set a threshold and rebuild.





---


## 5. Next Steps

- Research Prefect for DAG orchestration and RabbitMQ for job queuing.
- Define folder structure by processing group rather than execution order.
- Create template files: `template_cpu_worker.py`, `template_gpu_worker.py`, `template_gpu_dispatch.py`.
- Implement `lib/compute.py` for parallel CPU task management.
- Implement addional repeated methods that the pipeline can pull from `lib/logging`, `lib/contract.py`, `lib/config.py`, `lib/core_orchestration.py`, `lib/utils.py`, `lib/paths.py` and possible `lib/validation.py`
- Establish an imporved `config/pipeline.yaml` as single source for all hyperparameters, cpu batches and workers. Also include GPU profiles to not limit the pipeline to hardware compute.
- Design validation schema and `report.json` contract for cross-stage collation. Each script can have a report output that could be colated together as a final pass/fail for each PDF.
- Benchmark per-stage timing with current hardware configuration and record per-PDF timing through entire pipeline for the manifest.




