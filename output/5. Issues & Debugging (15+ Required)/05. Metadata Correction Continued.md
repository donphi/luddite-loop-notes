## Issues & Debugging (15+ Required) — Issue 5: Metadata Correction (Continued)

**Description:**  
# DOI and Title Matching Investigation

## Background
- While removing validated issue files, noticed some UK Biobank PDFs were being incorrectly removed.
- Investigated the matching process further.
- Found that some DOI numbers were being truncated due to Python word extraction library limitations.
- Decided to test title matching as a secondary match key when DOI is missing or malformed.

---

## Rationale
- DOIs often contain punctuation and formatting variations → increases parsing errors.
- Titles provide another matching vector, but need a statistically valid method to avoid false positives.
- Objective: determine minimum sequence length of words for high-probability uniqueness.

---

## Method Chosen: 3-Word Shingle + Jaccard Similarity
<image placeholder - 3-word shingle equation>Algorithm (Broder's Near-Duplicate Detection):
1. Tokenize both titles into words (exclude ≤2-char stop words).
2. Create 3-word shingles (sliding window of 3 consecutive words).
3. Compute Jaccard similarity:
\( r = \frac{|S_1 \cap S_2|}{|S_1 \cup S_2|} \)
4. Apply threshold: r ≥ 0.80 → strong match.

---

## Matching Rules
- Jaccard ≥ 0.80 + year match → 95% confidence (very strong match).
- Jaccard ≥ 0.85 (no year) → use Jaccard score as confidence level.
- Fallback: exact match or fuzzy matching if shingle score < 0.80.

---

## Scientific Advantages
- Robust to word reordering → shingles preserve local context.
- Handles small variations → tolerant to minor edits.
- Proven → based on Broder’s widely cited work in IR.
- Established threshold → 0.80 is accepted for near-duplicate detection.

---

## Result
- Tested against 441 unmatched PDFs.
- Only 1 PDF successfully matched via title shingle method.
- Conclusion: not worth implementing in main pipeline due to minimal gain.

<image placeholder - matching attempt summary chart>  

**summary:** The problem identified was the incorrect removal of UK Biobank PDFs due to truncated DOI numbers during the matching process. The proposed solution involved using a title matching method based on 3-word shingles and Jaccard similarity to address missing or malformed DOIs, but it ultimately proved ineffective, matching only one out of 441 PDFs tested.  
**Resolved:** ✓  
**Date:** 2025-08-10  
**Hours:** 3  
**Category:** Data Processing  
**Solution:** ## Result

- Tested against 441 unmatched PDFs.
- Only 1 PDF successfully matched via title shingle method.
- Conclusion: not worth implementing in main pipeline due to minimal gain.  
**Issue:** Metadata Correction (Continued)  

## Content


# DOI and Title Matching Investigation


## Background

- While removing **validated issue files**, noticed some **UK Biobank PDFs** were being incorrectly removed.
- Investigated the matching process further.
- Found that some DOI numbers were being **truncated** due to Python word extraction library limitations.
- Decided to test **title matching** as a secondary match key when DOI is missing or malformed.

---


## Rationale

- DOIs often contain **punctuation and formatting variations** → increases parsing errors.
- Titles provide another matching vector, but need a statistically valid method to avoid false positives.
- Objective: determine **minimum sequence length** of words for high-probability uniqueness.

---


## Method Chosen: 3-Word Shingle + Jaccard Similarity






$$
\text{Given a token sequence } T = (w_1, w_2, \dots, w_n), \\
\text{the set of 3-word shingles is:} \\
S_3 = \{ (w_i, w_{i+1}, w_{i+2}) \mid 1 \leq i \leq n-2 \}
$$


$$
R = \frac{|S_3^{(A)} \cap S_3^{(B)}|}{|S_3^{(A)} \cup S_3^{(B)}|}
$$






$$
S_3(A) = \text{set of trigrams from title $A$} \\
S_3(B) = \text{set of trigrams from title $B$} \\
R = \text{Jaccard similarity score (0 to 1)}
$$






$$
S_3(A) = \{ (w_i, w_{i+1}, w_{i+2}) \mid 1 \leq i \leq n_A - 2 \} \\
S_3(B) = \{ (v_j, v_{j+1}, v_{j+2}) \mid 1 \leq j \leq n_B - 2 \} \\
R = \frac{|S_3(A) \cap S_3(B)|}{|S_3(A) \cup S_3(B)|}, \quad 0 \leq R \leq 1
$$










Algorithm (Broder's Near-Duplicate Detection):


1. **Tokenize** both titles into words (exclude ≤2-char stop words).
2. **Create 3-word shingles** (sliding window of 3 consecutive words).
3. **Compute Jaccard similarity**:
\( r = \frac{|S_1 \cap S_2|}{|S_1 \cup S_2|} \)
4. **Apply threshold**: r ≥ 0.80 → strong match.

---


## Matching Rules

- **Jaccard ≥ 0.80 + year match** → 95% confidence (very strong match).
- **Jaccard ≥ 0.85 (no year)** → use Jaccard score as confidence level.
- **Fallback**: exact match or fuzzy matching if shingle score < 0.80.

---


## Scientific Advantages

- **Robust to word reordering** → shingles preserve local context.
- **Handles small variations** → tolerant to minor edits.
- **Proven** → based on Broder’s widely cited work in IR.
- **Established threshold** → 0.80 is accepted for near-duplicate detection.

---


## Result

- Tested against 441 unmatched PDFs.
- **Only 1 PDF** successfully matched via title shingle method.
- **Conclusion**: not worth implementing in main pipeline due to minimal gain.
















