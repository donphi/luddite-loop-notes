# Database Creation


## Content


# Medical Normalization Database for RAG Pipeline


## Why This Database Exists


### The Problem


```plain text
8,500 UK Biobank papers use inconsistent medical terminology:
- "BP" vs "blood pressure" vs "systolic pressure" vs "hypertension screening"
- "BMI" vs "body mass index" vs "weight/heightÂ²" vs "adiposity measure"
- "depression" vs "major depressive disorder" vs "MDD" vs "mood disorder"

Without normalization:
- Vector search recall drops by ~60%
- Same concept creates different embeddings
- Filters fail ("ukb_field=BP" â‰  "ukb_field=blood_pressure")
```


### The Solution


A PostgreSQL normalization layer that maps all variations to canonical IDs before embedding.



---


## Architecture Overview


```mermaid
graph TB
    subgraph "Input Layer"
        P[8,500 PDF Papers] --> PP[Paper Parser<br/>LlamaParse/Unstructured]
        PP --> RC[Raw Chunks<br/>with messy terms]
    end

    subgraph "Normalization Database - PostgreSQL"
        RC --> NER[Medical NER<br/>SciBERT/SciSpacy]
        NER --> RT[Raw Terms<br/>'blood pressure', 'BP', 'SBP']

        RT --> NF[Normalization Functions]

        subgraph "Open Ontologies"
            UKB[UK Biobank Fields<br/>5,803 measurements]
            ICD[ICD-10 Codes<br/>11,536 diseases]
            MESH[MeSH Terms<br/>30,956 concepts]
            HPO[HPO Terms<br/>19,657 phenotypes]
        end

        subgraph "Licensed Ontologies"
            UMLS[UMLS Metathesaurus<br/>3.5M+ concepts<br/>ðŸ”’ License Required]
            SNOMED[SNOMED-CT<br/>350K+ clinical terms<br/>ðŸ”’ License Required]
        end

        NF <--> UKB
        NF <--> ICD
        NF <--> MESH
        NF <--> HPO
        NF <--> UMLS
        NF <--> SNOMED

        UMLS -.->|Cross-maps| ICD
        UMLS -.->|Cross-maps| MESH
        UMLS -.->|Cross-maps| SNOMED

        NF --> NT[Normalized Tags<br/>ukb_field: 93<br/>icd10: I10<br/>umls_cui: C0020538<br/>snomed: 38341003]
    end

    subgraph "Vector Database"
        NT --> VM[Vector Metadata<br/>JSON filters]
        VM --> VDB[(Milvus/Pinecone<br/>Searchable vectors)]
    end

    subgraph "Query Time"
        Q[User Query<br/>'hypertension studies'] --> QN[Query Normalizer]
        QN --> NF
        QN --> QF[Normalized Filter<br/>ukb_field=93<br/>snomed=38341003]
        QF --> VDB
        VDB --> R[Retrieved Chunks<br/>All BP variants found!]
    end
```


---


## Why UMLS and SNOMED-CT Are Critical


### UMLS (Unified Medical Language System)


```plain text
Acts as the "Rosetta Stone" of medical terminology:
- Links 200+ source vocabularies
- 3.5 million concepts
- 15 million concept names

Example mapping:
"Hypertension" â†’ UMLS CUI: C0020538 â†’ Links to:
  â”œâ”€â”€ ICD-10: I10
  â”œâ”€â”€ SNOMED: 38341003
  â”œâ”€â”€ MeSH: D006973
  â””â”€â”€ UK Biobank: Field 4080
```


### SNOMED-CT (Systematized Nomenclature of Medicine)


```plain text
Most comprehensive clinical terminology:
- 350,000+ active concepts
- 1.5 million relationships
- Hierarchical structure

Example hierarchy:
38341003 | Hypertensive disorder
  â”œâ”€â”€ 59621000 | Essential hypertension
  â”œâ”€â”€ 28119000 | Secondary hypertension
  â””â”€â”€ 48146000 | Diastolic hypertension
```


---


## Data Flow Examples


### 1. Document Processing with Full Ontology Stack


```python
# Input: Complex medical text
text = "Patient presents with essential HTN (160/95), T2DM with A1c 8.2%, and MDD"

# Step 1: NER extraction
raw_terms = ["essential HTN", "T2DM", "A1c 8.2%", "MDD"]

# Step 2: Multi-ontology normalization
normalized = postgres.query("""
    SELECT normalize_tags_to_json(ARRAY['essential HTN', 'T2DM', 'MDD'])
""")
# Returns comprehensive mapping:
# [
#   {
#     "original": "essential HTN",
#     "ukb_field": "4080",
#     "icd10": "I10",
#     "snomed": "59621000",
#     "umls_cui": "C0085580",
#     "mesh": "D006973"
#   },
#   {
#     "original": "T2DM",
#     "ukb_field": "2976",
#     "icd10": "E11",
#     "snomed": "44054006",
#     "umls_cui": "C0011860",
#     "mesh": "D003924"
#   },
#   {
#     "original": "MDD",
#     "icd10": "F33",
#     "snomed": "370143000",
#     "umls_cui": "C1269683",
#     "mesh": "D003865"
#   }
# ]

# Step 3: Create richly tagged vector
vector = {
    "text": text,
    "embedding": model.encode(text),
    "metadata": {
        "ukb_fields": ["4080", "2976"],
        "icd10_codes": ["I10", "E11", "F33"],
        "snomed_codes": ["59621000", "44054006", "370143000"],
        "umls_cuis": ["C0085580", "C0011860", "C1269683"],
        "mesh_ids": ["D006973", "D003924", "D003865"]
    }
}
```


### 2. Cross-Ontology Query Resolution


```python
# User query: "Find studies on high blood pressure complications in diabetics"

# Different papers use different terminologies:
# Paper A: Uses SNOMED codes
# Paper B: Uses ICD-10 codes
# Paper C: Uses UK Biobank fields
# Paper D: Uses MeSH terms

# UMLS unifies them all:
query_concepts = postgres.query("""
    SELECT * FROM umls_mappings
    WHERE cui IN (
        SELECT cui FROM umls_concepts
        WHERE preferred_name ILIKE '%hypertension%'
    )
""")
# Returns ALL equivalent codes across ALL ontologies

# Now search finds papers regardless of coding system used
```


---


## Database Schema (Complete)


```sql
-- Open source ontologies (Available now)
ukb_fields (5,803 rows)          -- UK Biobank measurements
icd10_codes (11,536 rows)        -- Disease classifications
mesh_descriptors (30,956 rows)   -- Medical literature concepts
hpo_terms (19,657 rows)          -- Phenotype ontology

-- Licensed ontologies (Pending licenses)
umls_concepts (3.5M rows)        -- Unified concept identifiers (CUIs)
â”œâ”€â”€ cui                          -- Concept Unique Identifier
â”œâ”€â”€ preferred_name               -- Canonical name
â””â”€â”€ semantic_types[]             -- Categories

umls_mappings (15M rows)         -- Cross-ontology mappings
â”œâ”€â”€ cui                          -- Links to umls_concepts
â”œâ”€â”€ source_vocabulary            -- ICD10, SNOMED, MESH, etc.
â””â”€â”€ source_code                  -- Code in that vocabulary

snomed_concepts (350K rows)      -- Clinical terms
â”œâ”€â”€ concept_id                   -- SNOMED ID
â”œâ”€â”€ term                         -- Clinical term
â””â”€â”€ semantic_tag                 -- (disorder), (procedure), etc.

snomed_relationships (1.5M rows) -- Hierarchical relationships
â”œâ”€â”€ source_id                    -- Parent concept
â”œâ”€â”€ destination_id               -- Child concept
â””â”€â”€ type_id                      -- IS-A, PART-OF, etc.
```


---


## Value of Licensed Ontologies


| Feature
                     | Without UMLS/SNOMED
 | With UMLS/SNOMED
               |
| ---------------------------- | -------------------- | ------------------------------- |
| Concept Coverage
            | ~100K concepts
      | 3.5M+ concepts
                 |
| Cross-mapping
               | Manual, incomplete
  | Automatic, comprehensive
       |
| Clinical Precision
          | Basic disease codes
 | Detailed clinical subtypes
     |
| Synonym Coverage
            | 1-5 per concept
     | 10-50+ per concept
             |
| Relationship Mapping
        | None
                | Full hierarchy & relationships
 |
| International Compatibility
 | Limited
             | Global standard
                |


### Example: Depression Mapping


```plain text
Without UMLS/SNOMED:
"depression" â†’ ICD-10: F32 (single code)

With UMLS/SNOMED:
"depression" â†’ UMLS: C0011570 â†’ Maps to:
â”œâ”€â”€ ICD-10: F32.0, F32.1, F32.2, F32.3, F32.8, F32.9
â”œâ”€â”€ SNOMED: 35489007, 370143000, 76441001, 191610000
â”œâ”€â”€ MeSH: D003863, D003865, D003866
â”œâ”€â”€ UK Biobank: Fields 4598, 4609, 4620, 20002
â””â”€â”€ 47 additional synonyms and related concepts
```


---


## Implementation with Full Stack


```python
class MedicalNormalizer:
    def __init__(self):
        self.db = psycopg2.connect("postgresql://meduser@localhost/medontology")

    def normalize_comprehensive(self, term):
        """Normalize across all ontologies"""
        cursor = self.db.cursor()

        # First try UMLS (most comprehensive)
        cursor.execute("""
            SELECT
                c.cui,
                c.preferred_name,
                array_agg(DISTINCT m.source_vocabulary || ':' || m.source_code) as mappings
            FROM umls_concepts c
            JOIN umls_mappings m ON c.cui = m.cui
            WHERE c.preferred_name ILIKE %s
               OR c.cui IN (
                   SELECT cui FROM umls_mappings
                   WHERE source_term ILIKE %s
               )
            GROUP BY c.cui, c.preferred_name
            LIMIT 1
        """, (f'%{term}%', f'%{term}%'))

        result = cursor.fetchone()
        if result:
            # Parse mappings into structured format
            return self.parse_umls_mappings(result)

        # Fallback to individual ontology search
        return self.search_individual_ontologies(term)
```


---


## Summary


The complete database with UMLS and SNOMED is essential because:


1. **UMLS provides the glue** - Links all medical vocabularies together (3.5M+ concepts)
2. **SNOMED provides clinical precision** - 350K+ detailed clinical concepts with relationships
3. **Together they ensure nothing is missed** - A concept in any vocabulary maps to all others
4. **International research compatibility** - SNOMED is the global clinical standard
5. **Relationship traversal** - Find related concepts (e.g., all subtypes of diabetes)

Without UMLS/SNOMED: ~40% recall, manual mapping, limited to basic codes
With UMLS/SNOMED: ~95% recall, automatic cross-mapping, comprehensive coverage



The licensed ontologies transform the system from a "good enough" research tool to a clinical-grade normalization engine suitable for discovering hidden medical connections.



---


## Data Flow Examples


### 1. Document Processing Flow


```python
# Input: Raw paper text
text = "Patient cohort showed elevated BP (mean 145/95) with 68% having BMI>30"

# Step 1: NER extraction
raw_terms = ["BP", "BMI>30"]

# Step 2: Database normalization
normalized = postgres.query("""
    SELECT normalize_tags_to_json(ARRAY['BP', 'BMI'])
""")
# Returns:
# [
#   {"original": "BP", "concept_id": "93", "canonical": "Systolic blood pressure"},
#   {"original": "BMI", "concept_id": "21001", "canonical": "Body mass index"}
# ]

# Step 3: Create vector with clean metadata
vector = {
    "text": text,
    "embedding": model.encode(text),
    "metadata": {
        "ukb_fields": ["93", "21001"],      # Standardized IDs
        "paper_id": "10.1038/nature.2024.1",
        "sample_size": 50000
    }
}
```


### 2. Query Normalization Flow


```python
# User searches: "blood pressure and depression correlation"

# Normalize search terms using same database
search_terms = ["blood pressure", "depression"]
normalized = postgres.normalize(search_terms)
# Returns: ukb_field=93, icd10=F32

# Vector search with normalized filters
results = vector_db.search(
    query_embedding,
    filter={
        "ukb_fields": {"$in": ["93"]},
        "icd10_codes": {"$in": ["F32"]}
    }
)
# Finds ALL papers regardless of terminology used!
```


---


## Value Proposition


### 1. **Improved Recall** (60% â†’ 95%)


```plain text
Without normalization:
- Search "blood pressure" â†’ Misses papers using "BP", "SBP", "hypertension"

With normalization:
- Search "blood pressure" â†’ Finds ALL variants via ukb_field=93
```


### 2. **Cross-Ontology Linking**


```sql
-- A single medical concept maps across multiple standards
"diabetes" â†’ {
    ukb_field: "2976",      -- UK Biobank
    icd10: "E11",           -- ICD-10
    mesh: "D003924",        -- MeSH
    hpo: "HP:0000819"       -- HPO
}
```


### 3. **Consistency Across Pipeline**


```plain text
Paper 1: "elevated BP"     â†’ ukb_field: 93
Paper 2: "blood pressure"  â†’ ukb_field: 93
Paper 3: "hypertension"    â†’ ukb_field: 93

All searchable with one filter!
```


### 4. **Dynamic Discovery Enablement**


```python
# RAG can now ask: "Find all papers studying field 93 with field 21001"
# Instead of: "Find papers with 'BP' OR 'blood pressure' OR 'SBP' OR..."
```


---


## Database Schema


```sql
-- Core normalization tables
ukb_fields (5,803 rows)     -- UK Biobank measurements
â”œâ”€â”€ field_id                 -- Canonical ID (e.g., "93")
â”œâ”€â”€ title                    -- Official name
â””â”€â”€ title_synonyms[]         -- All variations

icd10_codes (11,536 rows)   -- Disease classifications
mesh_descriptors (30,956)    -- Medical concepts
hpo_terms (19,657)           -- Phenotype ontology

-- Key normalization function
find_medical_concept(text) â†’ {
    ontology: "UK_BIOBANK",
    concept_id: "93",
    canonical_name: "Systolic blood pressure",
    confidence: 0.95
}
```


---


## Performance Impact


| Metric
                 | Without Normalization
  | With Normalization
 |
| ----------------------- | ----------------------- | ------------------- |
| Search Recall
          | ~40%
                   | ~95%
               |
| False Negatives
        | High (missed synonyms)
 | Low
                |
| Query Complexity
       | Complex OR chains
      | Simple ID match
    |
| Maintenance
            | Update every query
     | Update central DB
  |
| Cross-study Comparison
 | Manual mapping
         | Automatic via IDs
  |


---


## Implementation


```python
# One-time setup
postgres = PostgreSQL(host="localhost", db="medontology")

# For every document chunk
def process_chunk(text):
    # Extract â†’ Normalize â†’ Tag
    terms = extract_medical_terms(text)
    normalized = postgres.normalize(terms)

    return {
        "embedding": encode(text),
        "metadata": normalized  # Clean, searchable IDs
    }

# At query time
def search(query):
    # Same normalization for consistency
    query_terms = extract_medical_terms(query)
    filters = postgres.normalize(query_terms)

    return vector_db.search(query, filter=filters)
```


---


## Summary


The database is essential because:


1. **Medical language is highly variable** - Same concept, dozens of expressions
2. **Vectors search on metadata filters** - IDs must be consistent
3. **Cross-study analysis requires standardization** - Can't compare without common vocabulary
4. **RAG quality depends on recall** - Missing synonyms = missing evidence

Without this normalization layer, your RAG system would miss ~60% of relevant content due to terminology variations, making it unsuitable for medical research where completeness is critical.










