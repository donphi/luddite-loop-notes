## Activity Log (80+ Required) â€” Entry 6: PDF Metadata Matching

**Hours:** 4  
**Date:** 2025-08-07  
**Next Steps:** The next step involves shifting from metadata-only matching to full-text extraction using the Marker tool to convert entire PDFs into structured Markdown and JSON, thereby eliminating the single point of failure and enabling richer downstream tasks.  
**Category:** ðŸ§¹ Data Preprocessing  
**Summary:**  
The PDF Metadata Matching Workflow aims to programmatically link scientific PDFs to their bibliographic metadata with high accuracy, achieving a 96.1% match rate through automated extraction and validation processes. The next step involves shifting to full-text extraction to enhance the matching capabilities and reduce dependency on metadata alone.  

**Related Experiments:**  
- PDF to Markdown/JSON Conversion  

**Nr:** 6  
**Phase:** Phase 2: PDF Processing Pipeline  
**Entry:** PDF Metadata Matching  

## Content


```markdown
# PDF Metadata Matching Workflow

## Objective
Programmatically link scientific PDFs to their bibliographic metadata. Each document must be accurately identified and enriched with DOI, title, authors, and publication year. This ensures downstream stages operate on verified, properly indexed data. The process is automated, statistically validated, and designed to withstand academic scrutiny.

---

## Process

1. **Environment**
   - Docker container for reproducibility.  
   - GROBID server provides machine-learning based parsing of scientific articles.  

2. **Metadata Extraction**
   - `grobid_matcher.py` iterates through PDFs.  
   - Extracts headers: title, authors, DOI.  

3. **Indexing**
   - `publications_index.json` loaded into fast lookup dictionaries for DOIs and titles.  

4. **Matching Logic**
   - First attempt: DOI â†’ index (high confidence).  
   - If DOI missing or fails:  
     - Title similarity (BM25 + fuzzy matching).  
     - Author list overlap.  
     - Publication year proximity.  

5. **Validation Layer**
   - `scientific_validation.py` recalculates match confidence.  
   - Checks author overlap, title similarity, and year deltas.  
   - Flags mismatches for manual review.  

---

## Validation

- **Sample Size**: 363 docs out of 6,400.  
- **Observed Accuracy**: 96.1%.  
- **95% CI**: 93.6%â€“97.7%.  
- **Margin of Error**: Â±2.0%.  
- **Significance**: statistically valid (p < 0.05).  

**Match Breakdown**:  
- DOI-based: 96.9% (323 docs).  
- Fuzzy title: 88.9% (27 docs).  
- Exact title: 100% (4 docs).  
- Partial DOI: 88.9% (9 docs).  

---

## Reflection
- Overall accuracy excellent at 96.1%.  
- Single major dependency: GROBID extraction.  
- If GROBID fails (corrupt file, unusual layout, timeout), the PDF becomes unmatchable.  
- This creates a bottleneck where PDFs are flagged `unreadable` or `extraction_failed`.  
- Lesson learned: relying only on header metadata is fragile â€” quality of full-text extraction is the real upstream driver.  

---

## Next Step
Shift from metadata-only to **full-text extraction**:  

- Adopt `Marker` tool in `1_pdf_to_md_json`.  
- Convert the entire PDF into structured Markdown + JSON.  
- Marker advantages:  
  - Full OCR with Tesseract + Surya.  
  - Tables, equations, and images preserved.  
  - Hybrid speed/quality modes.  
  - GPU acceleration for scale.  

This pivot eliminates the single point of failure in metadata-only matching and enables richer downstream tasks (e.g., NER, feature tagging) on the full content.
```

