# Data Validation - Duplicate Rem


## Content


```markdown
# UKB Data Validation – Duplicate Removal

## Objective
Identify and remove duplicate JSON/Markdown file pairs using DOI matching and metadata quality scoring. This step ensures data integrity by eliminating redundant entries while keeping only the highest-quality version of each document.

---

## Process

1. **Duplicate Detection**
   - All JSON files (main + missing directories) analyzed with `metadata_analyser.py`.  
   - DOIs normalized to ISO 26324 standards using `robust_doi_matcher.py`.  
   - Found **303 duplicate DOI groups** with multiple files pointing to the same DOI.  

2. **Quality-Based Selection**
   - Each duplicate group scored on:  
     - `extraction_quality_score` (0–1).  
     - `extraction_completeness` (0–1).  
     - `doi_exact_match` (boolean).  
   - Scores combined into a composite metadata score.  
   - Highest scoring file kept; others flagged for removal.  

3. **File Management**
   - Duplicate files moved to a backup directory at `/data/ukb/json_validation_issue/`.  
   - Scripts generated directory structures, validated moves, and logged all actions.  
   - Safety checks prevented accidental overwrites.  

---

## Validation

Comparison of quality distribution between kept vs deleted files:

| Quality Level | Files Kept | % of Kept | Files Deleted | % of Deleted |
|---------------|------------|-----------|---------------|--------------|
| Perfect (EQ=1.0, EC=1.0, DOI=True) | 28 | 12.8% | 13 | 4.3% |
| High Quality (EQ ≥ 0.9) | 119 | 54.6% | 106 | 35.0% |
| Medium Quality (EQ ≥ 0.7) | 66 | 30.3% | 137 | 45.2% |
| Low Quality (EQ < 0.7) | 5 | 2.3% | 47 | 15.5% |

**Result**: 67.4% of kept files scored High or Perfect, confirming the scoring algorithm prioritized quality.

---

## Reflection
- 303 duplicate groups confirmed — a significant redundancy issue fixed before feature extraction.  
- The scoring system worked well, though in edge cases with similar scores, tie-breakers (metadata richness, content length) were needed.  
- ISO 26324 DOI normalization was essential — DOIs appear in multiple inconsistent formats in the literature.  
- Running in Docker containers provided reproducibility and isolated environments.  
- Trade-off: some high-quality duplicates were discarded when scores tied closely.  

---

## Next Step
Proceed to `3_extract_syn_ukb_features`: extract UK Biobank-specific features from the cleaned, deduplicated dataset.

---

## Technical Implementation

### Libraries
- **Python Standard**: `json`, `os`, `re`, `pathlib`, `collections`.  
- **Fast JSON**: `orjson`.  
- **DOI Handling**: `idutils` (CERN standard DOI normalization/validation).  
- **String Comparison**: `rapidfuzz` (Levenshtein distance for fuzzy matching).  
- **HTTP/Retry**: `httpx`, `tenacity` (for optional DOI verification).  
- **Progress**: `tqdm`.  

### Docker
Two container builds:  

1. **Dockerfile** – Standards-compliant DOI analysis:  
   ```dockerfile
   FROM python:3.11-slim
   RUN pip install --no-cache-dir orjson polars idutils rapidfuzz httpx tenacity tqdm
   
2. **Dockerfile.meta** – Metadata quality analysis:
	FROM python:3.11-slim
```


### Objective


Identify and remove duplicate JSON/Markdown file pairs using DOI matching and metadata quality scoring. This step ensures data integrity by eliminating redundant entries while keeping only the highest-quality version of each document.







---


### Process

1. **Duplicate Detection**
    - All JSON files (main + missing directories) analyzed with `metadata_analyser.py`.
    - DOIs normalized to ISO 26324 standards using `robust_doi_matcher.py`.
    - Found **303 duplicate DOI groups** with multiple files pointing to the same DOI.
2. **Quality-Based Selection**
    - Each duplicate group scored on:
        - `extraction_quality_score` (0–1).
        - `extraction_completeness` (0–1).
        - `doi_exact_match` (boolean).
    - Scores combined into a composite metadata score.
    - Highest scoring file kept; others flagged for removal.
3. **File Management**
    - Duplicate files moved to a backup directory at `/data/ukb/json_validation_issue/`.
    - Scripts generated directory structures, validated moves, and logged all actions.
    - Safety checks prevented accidental overwrites.

    



---


### Validation


Comparison of quality distribution between kept vs deleted files:



| Quality Level
                      | Files Kept
 | % of Kept
 | Files Deleted
 | % of Deleted
 |
| ----------------------------------- | ----------- | ---------- | -------------- | ------------- |
| Perfect (EQ=1.0, EC=1.0, DOI=True)
 | 28
         | 12.8%
     | 13
            | 4.3%
         |
| High Quality (EQ ≥ 0.9)
            | 119
        | 54.6%
     | 106
           | 35.0%
        |
| Medium Quality (EQ ≥ 0.7)
          | 66
         | 30.3%
     | 137
           | 45.2%
        |
| Low Quality (EQ < 0.7)
             | 5
          | 2.3%
      | 47
            | 15.5%
        |


Result: 67.4% of kept files scored High or Perfect, confirming the scoring algorithm prioritized quality.







---


### Reflection

- 303 duplicate groups confirmed — a significant redundancy issue fixed before feature extraction.
- The scoring system worked well, though in edge cases with similar scores, tie-breakers (metadata richness, content length) were needed.
- ISO 26324 DOI normalization was essential — DOIs appear in multiple inconsistent formats in the literature.
- Running in Docker containers provided reproducibility and isolated environments.
- Trade-off: some high-quality duplicates were discarded when scores tied closely.





---


### Next Step


Proceed to 3_extract_syn_ukb_features: extract UK Biobank-specific features from the cleaned, deduplicated dataset.







---


### Technical Implementation


Libraries


- **Python Standard**: `json`, `os`, `re`, `pathlib`, `collections`.
- **Fast JSON**: `orjson`.
- **DOI Handling**: `idutils` (CERN standard DOI normalization/validation).
- **String Comparison**: `rapidfuzz` (Levenshtein distance for fuzzy matching).
- **HTTP/Retry**: `httpx`, `tenacity` (for optional DOI verification).
- **Progress**: `tqdm`.





Docker



Two container builds:


1. **Dockerfile** – Standards-compliant DOI analysis:

    ```docker
    FROM python:3.11-slim
    RUN pip install --no-cache-dir orjson polars idutils rapidfuzz httpx tenacity tqdm
    ```

2. **Dockerfile.meta** – Metadata quality analysis:
FROM python:3.11-slim
