# PDF Retrieval


## Content


### **Objective**


In my pursuit of compiling a comprehensive dataset of UK Biobank journals I had to contact a few sources. I had already been able to download over six million full-text PubMed journal papers, very easily on their platfrom which is open to the public, perfectly in a structured json format with the idea of finding links between the two sources.



I engaged with platforms such as Core.ac.uk and OpenAlex, both of which could provide a substantial corpus of about 120 to 200 million JSON files containing full-text journal articles. However, I encountered a notable limitation, as neither a unique search was needed through an API or a license for access. In hindsight, utilizing OpenAlex with a DOI API scanner would have been particularly beneficial. Unfortunately, Westminister had limited access to full-text journal papers through Core.ac.uk.



Thus, the primary challenge remained: to systematically locate PDF (which inherently were full text) versions of Biobank-related articles across various repositories. This would require developing targeted scripts at each open sourced repositories to search for matching DOIs matching, followed by cross-referencing journal titles for verification.







---


### **Process**

- Attempted automated retrieval using **Playwright** in Python; this approach failed.
- Transitioned to the **Selenium** library with simpler button-finding methods. This helped and was able
- Configured a **WireGuard server** to protect IP identity during automated retrieval.
- Successfully downloaded ~485 PDFs before access was interrupted, suggesting restrictions by the source platform.





---


### **Technical**


To support retrieval of Biobank-related publications, I developed scripts for metadata extraction, download automation, and content verification. These were ultimately not used in the final dataset (for compliance reasons) but illustrate the systematic approach explored.







1. Metadata Extraction


- Parsed tab-delimited files (publications.txt).
- Extracted DOIs, authors, journal names, and URLs.
- Cleaned titles and DOIs for safe filenames.
- Maintained a JSON index to avoid duplicates.

    Example log:
    


    Saved index with 12,487 publications | Extracted 214 new URLs
    


    



2. Automated Download & Verification


- Used requests, BeautifulSoup, and PyPDF2 to fetch and check PDFs.
- Validated file size (>10 KB), page count, and presence of text.
- Logged successes and failures with progress tracking (tqdm).

    Example:
    


    Valid PDF with 12 pages: 2024_Yang_Activity.pdf
    


    PDF too small (3 KB): invalid.pdf
    


    



3. Authentication Handling


- Attempted institutional login (Shibboleth, basic auth).
- Frequent failures due to restricted domains.

    Log:
    


    Domain openaccess.city.ac.uk requires auth: True | Failed to click on Shibboleth button
    


    



4. Process Management


- Companion script to terminate stuck Python/Docker download jobs for reproducibility.





5. Output Example



9982|10.1016j.ebiom.2024.105075|Lang|Using_generative_AI_to_investigate|pdf|http://thelancet.com/...







---


### **Reflection**


Following discussion with my course leaders, we agreed this retrieval method was unsuitable and should not be included in the project. Instead, the decision was taken to rely only on publications accessible through Westminster University subscriptions or available as open access. This ensures compliance with research integrity and avoids any methodological risks associated with non-approved retrieval strategies:contentReference[oaicite:3]{index=3}.







---


### **Next Step**


Proceed with dataset construction using only institutionally accessible and open access journal papers, employing whichever approved retrieval method is most reliable.






