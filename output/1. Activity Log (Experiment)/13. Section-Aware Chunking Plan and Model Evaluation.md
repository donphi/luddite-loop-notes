# Section-Aware Chunking Plan and Model Evaluation


## Content


### Objective


Develop a robust system to categorize 10,416 UK Biobank section headers that were previously misclassified as "supplementary_chain" into appropriate biomedical categories. This improves data organization and enables better search/retrieval for downstream NLP tasks by properly classifying research paper sections (methods, results, funding, ethics, etc.).







---


### Process

1. **Data Extraction and Cleaning**
    - Input: `section_mapping_with_transitions.json` containing misclassified sections
    - Extracted 10,416 items marked as "supplementary_chain"
    - Generated clean text file (`sections_clean.txt`) removing formatting artifacts
    - Purpose: Prepare sanitized input for vectorization and DuckDB storage
2. **Embedding Model Selection**
    - Evaluated 11 state-of-the-art embedding models:
        - **Biomedical-specific**: BiomedBERT, BioBERT, SciBERT, SapBERT, MedCPT, BioLinkBERT
        - **Scientific**: SPECTER2
        - **General-purpose**: BGE-M3, all-mpnet-base-v2, e5-large-v2
        - **High-dimensional**: NVIDIA NV-Embed-v2 (4096d)
    - Dimensions ranged from 768d to 4096d
3. **Categorization Framework**
    - **9 target categories**:
        - `title_subtitle`: Research paper titles
        - `methods`: Experimental procedures
        - `results`: Findings and outcomes
        - `statistical_analysis`: Statistical methods
        - `data_availability`: Data access statements
        - `funding`: Grant information
        - `ethics`: IRB approvals
        - `author_info`: Author details
        - `conflict_interest`: COI declarations
    - **Exemplar-based approach**: 89 carefully curated exemplars across categories
    - **Cosine similarity threshold**: 0.4 for category assignment
4. **Containerization and GPU Acceleration**
    - Docker container with CUDA 12.9 + PyTorch 2.9.0
    - NVIDIA RTX PRO 6000 Blackwell (95GB VRAM)
    - Batch processing (256 items for 768d models, 32 for 4096d)
    - Mixed precision (AMP) for speed optimization
5. **Model Performance Scoring**
    - Developed composite scoring system (0-100):
        - Mean confidence: 40% weight
        - Categorization rate: 30% weight
        - Distribution balance: 20% weight
        - High confidence items (>0.7): 10% weight
6. **Cross-Model Validation**
    - Implemented "judge model" system using all-mpnet-base-v2 as neutral evaluator
    - Metrics:
        - **Coherence**: Similarity within categories
        - **Separation**: Distinctiveness between categories
        - **Accuracy**: Match with ground truth exemplars
        - **Coverage**: Percentage properly categorized
        - **Balance**: Even distribution across categories

    



---


### Results


BiomedBERT Performance (Best Model):


- **Model Score**: 91.06/100
- **Mean Confidence**: 0.949
- **Categorization Rate**: 100% (0 items in "other")
- **High Confidence Items**: 100%

Distribution:





~~~{=html}
<pre class="notion-ascii-diagram"><code>methods:              3,395 items
title_subtitle:       2,203 items
author_info:          2,137 items
statistical_analysis: 1,274 items
results:                938 items
funding:                214 items
data_availability:      129 items
ethics:                 101 items
conflict_interest:       25 items
other:                    0 items</code></pre>
~~~

~~~{=latex}
\begin{Verbatim}[commandchars=\\\{\}]
methods:              3,395 items
title_subtitle:       2,203 items
author_info:          2,137 items
statistical_analysis: 1,274 items
results:                938 items
funding:                214 items
data_availability:      129 items
ethics:                 101 items
conflict_interest:       25 items
other:                    0 items
\end{Verbatim}
~~~








---


### Reflection

1. **Model Architecture Impact**
    - Biomedical-specific models (BiomedBERT, BioBERT) significantly outperformed general models
    - Higher dimensions (4096d NVIDIA) didn't guarantee better performance
    - Domain-specific training trumped model size
2. **Technical Challenges**
    - NVIDIA NV-Embed-v2 required specific package versions (transformers==4.42.4)
    - Flash-attention compilation took 30+ minutes (ultimately skipped as non-essential)
    - Docker layer caching complicated package version updates
3. **Categorization Insights**
    - High concentration in `methods` (3,395) reflects biomedical literature's methodology focus
    - Very few `conflict_interest` items (25) - typically standardized phrases
    - 100% categorization rate indicates well-defined category boundaries
4. **Optimization Strategies**
    - Batch size tuning critical for memory management (256 vs 32)
    - Mixed precision (AMP) provided 2-3x speedup
    - Cache clearing every 10 batches prevented OOM errors
5. **Validation Architecture**
    - Self-scoring potentially biased; judge model provided objective comparison
    - Coherence + separation metrics balanced internal consistency vs distinctiveness
    - Ground truth exemplars essential for accuracy measurement

    



---


### Why This Approach


Vectorization Benefits:


- Dense embeddings enable semantic search beyond keyword matching
- Cosine similarity captures conceptual relationships
- Vector representations compatible with modern ML pipelines

DuckDB Integration:


- Columnar storage optimal for analytical queries
- Vector operations can leverage DuckDB's parallel execution
- Enables SQL-based semantic queries on categorized sections

Sanitization Rationale:


- Removed formatting artifacts that corrupt embeddings
- Standardized text encoding for consistent vectorization
- Clean data essential for reproducible results





---


### Next Steps

1. **Integration with Tagging Pipeline** (`data_conversion/ukb/4_tagging/`)
    - Apply categorized sections to improve NER model context
    - Use category information to select appropriate taggers
2. **DuckDB Storage**
    - Store embeddings as BLOB columns
    - Index by category for fast retrieval
    - Enable similarity searches within categories
3. **Production Deployment**
    - Implement API endpoint for real-time categorization
    - Cache embeddings for frequently accessed sections
    - Monitor model drift on new UK Biobank releases





---


## Section Normalization Proposal



<table>
  <thead>
    <tr>
      <th><strong>Paper Section Variants</strong></th>
      <th><strong>Normalized To</strong></th>
      <th><strong>Key Indicators</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Abstract, Summary</td>
      <td><code>abstract</code></td>
      <td>First section, &lt;300 words</td>
    </tr>
    <tr>
      <td>Introduction, Background, Literature Review</td>
      <td><code>introduction</code></td>
      <td>Problem statement, citations heavy</td>
    </tr>
    <tr>
      <td>Methods, Materials, Study Design, Participants</td>
      <td><code>methods</code></td>
      <td>Procedure description, sample info</td>
    </tr>
    <tr>
      <td>Results, Findings, Outcomes</td>
      <td><code>results</code></td>
      <td>Statistical results, figures/tables</td>
    </tr>
    <tr>
      <td>Discussion, Interpretation, Implications</td>
      <td><code>discussion</code></td>
      <td>Result interpretation, limitations</td>
    </tr>
    <tr>
      <td>Conclusion, Summary, Future Work</td>
      <td><code>conclusion</code></td>
      <td>Summary, future directions</td>
    </tr>
  </tbody>
</table>



---









